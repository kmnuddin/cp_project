{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MNE_Pipeline import MNE_Repo_Mat as MP\n",
    "import os\n",
    "import mne\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 files missing from /home/kam/anaconda3/envs/mne/lib/python3.7/site-packages/mne/datasets/_fsaverage/root.txt in /home/kam/mne_data/MNE-fsaverage-data\n",
      "0 files missing from /home/kam/anaconda3/envs/mne/lib/python3.7/site-packages/mne/datasets/_fsaverage/bem.txt in /home/kam/mne_data/MNE-fsaverage-data/fsaverage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/anaconda3/envs/mne/lib/python3.7/site-packages/mne/utils/docs.py:830: DeprecationWarning: Function read_montage is deprecated; ``read_montage`` is deprecated and will be removed in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_custom_montage``, or ``read_dig_captrack`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/kam/anaconda3/envs/mne/lib/python3.7/site-packages/mne/utils/docs.py:813: DeprecationWarning: Class Montage is deprecated; Montage class is deprecated and will be removed in v0.20. Please use DigMontage instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:34: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  montage.plot()\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAb4AAAG2CAYAAAAA3uOEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydd9hdVdG37x8JaSC9d0iAUITQexVUQEqU3kQQQfr7YcGCgFhQoiAiIEWQIiC9hSJNAgSkhUBI6EgJRekhoYX5/pj1mJPD6W2fMvd17et5zm4zZ5+91+yZNWuWzIwgCIIg6BVmyVqBIAiCIGglYfiCIAiCniIMXxAEQdBThOELgiAIeoowfEEQBEFPEYYvCIIg6CnC8AVBEAQ9RRi+IAiCoKcIwxcEQRD0FGH4giAIgp4iDF8QBEHQU4ThC4I2QpJJGpa1HkHQzYThC4ImI+lCSa9Kek/SU5K+nbVOQdDLKGZnCILmImkl4Bkz+0jScOBOYBsze6jAvgYsa2bPtFjNIOgZwuMLgiZjZhPM7KO+j2kZCiDp+8kbnCxp38yUDIIeIgxfELQASadJmgpMAl4FRkv6KvA9YEtgWWCLDFUMgp4hDF8QtAAzOwj4ArARcCXwEbAzcK6ZPW5mHwDHZqdhEPQOYfiCoEWY2XQzuxtYDPgusAjwUs4u/85EsSDoMcLwBUHr6Y/38b0KLJ6zfols1AmC3iIMXxA0EUkLSNpV0uyS+kn6CrAbcDvwd2AfSStKGgIck6myQdAjhOELguZieFjzZeBtYBRwhJldY2Y3AifjRvCZ9DcIgiYT4/iCIAiCniI8viAIgqCnCMMXBEEQ9BRh+IKgxcg5UtLNkubLWp8g6DXC8AVBC5HUD/gj8E1gInCvpKHZahUEvUX/rBUIgl4hDVm4GJgN2MjM3pU0Cbhb0g5mdn+2GgZBbxAeXxC0AEkLAHcA7wBbm9m7AGZ2BrA/cL2k7TNUMQh6hjB8QdBkJC0H3AvcBOxjZh/nbjez64GtgdMlHZyBikHQU8Q4viBoIpLWx4tS/8TMzimz7zLAjcA1wFFm9lkLVAyCniMMXxA0CUlfB84A9jazmyo8Zl7c8L2Me4cfNlHFIOhJItQZBE1A0uHAKcBXKjV6AGb2Jj4v3yzAzZLmaZKKQdCzhOELggYiaRZJJwEHABuY2SPVniN5ebsCDwL3SFqqoUoGQY8TwxmCoEFIGgxcAMyHG723az1X6t87UtK/ceO3nZk91CBVg6CnCY8vCBpAqsByK/AxHt6s2ejlYmanAIcAN0nauhHnDIJeJwxfENRJysa8BxgD7GlmHzXy/GZ2FbAd8BdJ+zfy3EHQi0RWZxDUgaS1gauB483s9CbLWhYf7nAJcLTFwxsENRGGLwhqRNJ2wNnAfmZ2XYtkzg9cBzyd5H5c5pAgCPKIUGcQ1ICkg/Axetu0yugBmNl/gM2BLwA3SpqzVbKDoFsIwxcEVZCGK/wGOBzY0MweaLUOZjYV+AbwBF7gevFW6xAEnUwYviCoEEkDgYuADYD1zey5rHQxs+nAYcB5+NRGq2alSxB0GmH4gqACJM0N3IKPfd0yVVjJFHN+BxwJ/EPSllnrFASdQBi+ICiDpCXx4QoPAruY2bSMVZoJM/s7Hvq8QNI+GasTBG1PZHUGQQkkrY5nUf4mDSZvWyQNB0YDfwV+HsMdgqAwYfiCoAiStgLOBw4wsyuz1qcSJC0EXA+Mx/X+JGOVgqDtiFBnEBRA0reBc4HtOsXoAZjZa8CmwIL4rO5zZKtRELQfYfiCIAc5xwNHARuZ2disdaoWM5sCbA+8ANwlaZFsNQqC9iIMXxAkJA3A+8e2xIcrPJ2xSjVjZp8CBwKXAmMlrZSxSkHQNsS0REEApAooVwBTgM3TIPGOJiW3/FrSi8AdknYxszuy1isIsiY8vqDnSZVP7gYmAd/oBqOXi5ldBOwCXCppj6z1CYKsCcMX9DSSVgHuxSugHJoqonQdydPbHPiVpB9JUtY6BUFWxHCGoGdJlU4uwg3epVUcNxDPmlwoZ1k4/Z0DGFTh0g/4sMJlKvAG8FrO8mr6+16lY/ZSosto4D7gkNQXGAQ9RRi+oCeRtBcwCtjRzMbkbZsLWCEtywOLMsOwLYTPjNBnhPqMz2vA68DbVG7MPgMGUpmRnA1YIE+PvmXWAro8A0xMy4tm9lnO95sDuAz4FNip20K7QVCOMHxBT5IGp3+IG43huJHr+zsE7+/rW15iZsPyVq4hyRpJszGzIVwEWJYZ32ce4Cn8u0xMf58GNgZO7dbwbhAUIwxf0PWk/qylgPXSsg5uEN5nZmPQ5yFN7qZyX5K+gHuuucZ9OLA08ArwMDA2LY+Y2UcZqRoELSEMX9B1SBoMrAGszwxj9xnesN+L929NMLN3MlOyDZA0KzAUWJMZ12pZ4FFmGMKxZjY5MyWDoAmE4Qs6HknzAFvg8+StB6yET9J6LzMa8Be7yYtrFpJmB9Zi5peGKcy4lrfjLw1xLYOOJQxf0HGk0OUqwNbANun/u9IyFngoEjYaQ7rWy+IGcAPgy4DwzNAbgDvM7IPsNAyC6gnDF3QEyRPZAjd2WwMf4Q3vDcA/zezDDNXrGZIhXIEZv8Oa+FyFo4HRZvZshuoFQUWE4QvaFklDgW1xr25dvG+uz9N4OsJt2ZNKveW+kLzLjN/onzFOMGhHwvAFbYWk+fHyWnvimZjX4g3pbWb2foaqBWWQNAswAjeA2wFLApcAFwIPxotK0C6E4QsyR9IQvKHcE9gQn0j1QuDW8Bg6F0nDgD3w33U6/pteZGbPZ6pY0POE4QsyQVI/YDO8UdweuB9vGK9O88kFXULqF1wb2Av35p/Ef+vLzOzNLHULepMwfEFLkTQc2A/YHa+EciFwSZo5POhy0tjBr+AvPFsBd+BzIF4X3n3QKsLwBU0n9f18FTgc7wP6C3CBmT2RqWJBpqSaoV8H9gcWA/4EnG1mb2WqWND1hOELmkYqlfVN4FDgA+APwKUx9CDIR9KawGF4Fu+lwCnxYhQ0i5iPL2g4kpaR9HvgBWBT4NvAGmb21zB6QSHM7EEz2xsfI/gacLukWyRtkyIGQdAwwuMLGkJKYNgMD2duAJwDnGZm/85UsaAjSXMe7oLfT3MAfwTOjSEtQSMIwxfURTJ42wHHAgOAU4ALo4xV0AjS/bU+bgC/BJwG/N7M3s5UsaCjCcMX1ERqkLYCfg70B44Bro1BykGzkLQ08FN8+MspwB/M7N1stQo6kTB8QVUkg7clbvBmxw3eVe00MWvQ3aSB8UfjL14nAX+MsZ9BNYThCypG0ma4wZsPD21eFgavOUiaDjyWs2oHM3shI3XakjQm9Bhgc+BEvE85ZuUIyhKGLyiLpA1xg7c4cBxwsZlNz1ar7kbSFDObPWs9OgFJK+MGcAPgN8CfI3s4KEWkCQdFkTRc0o3ABWlZwcwuDKOXDZL2kXSNpJskPSnpmLT+QEnj0vK8pDuy1rWVmNnjZrYTHvrcDHhG0t4xDCIoRnh8wedIFTWOBvYBfomHkD7OVKkuQ1J/oH8xzyQv1Pm8mY2UtA/wa2BlYCrwALCPmT2YjpkVnyH9t2Z2XZO/QtsiaR18+MOnwCFm9nDGKgVtRrwRBf9Dzp7ARGBeYGUzOzmMXuOQNJuk0/B566ZJuic11PlMM7MRaRmZs/4fZvammU0DrsRns+jjD8DtvWz0AMzsfnz+xnOA0ZLOkDRvxmoFbUQYvgAASSOAMcARwDfMbF8zez1jtbqRC4HvAkPS5/WB2yQtU+Hx+SEaAw+D4vPfHdcAHTseM/vMzM4BhgMfAU9I+m6aFSToccLw9TiS5kkeyM14lfx1zOy+jNVqKZKm5/SRjZO0VJn9/yLpDUmPVylnOWCHAptmw41hJWyZfrPB6Vz3SFoD+B6wZ7OybKu5RpIWl3SHpImSJkg6vBk6VYKZvWNmh+NDcHYFHpS0QVb6BO1B/6wVCLIhvfl+G8/WvAxPXOnVqvjTzGxEFfufB5wKnF+lnGElti1b4TnuxhONhgF/M7MHJZ0LzAPc4cMsedDMvl2lbuWo5hp9ChxpZg+nQuUPSfpHlkWnzWy8pE3xMmiXSLoT+IGZvZqVTkF2hOHrQZLn8Ve8gfqymT2asUptRwodjgQGAkvjRuY4ADO7q5xXWIQJeGhSBbaNz/1QYijDG2Z2SN6+36pBl7opdo2SMXk16fa+pInAokCmsy2kqkKXSLoe+AkwXtIPgPOi4lBvEaHOHkLSLJIOA+4FLgI2CaMHwOCcEN5VOevXBvbA5xDcKU2dUzOpYPdfCmz6D3B6PeduATVdo/SCsBpwf6sULYeZTTGzH+G1Pw8HrpG0UMZqBS0kDF+PkBqg2/B+jvXM7NReqLoiac/UWL8r6Z+SvlRgt1oyKGvlQNzbeBZ4Ew8zb1BJyM3Mzsv39hqBpPlS5uPrkl6TdKqkufN2q/oaSZoduAI4wszea7Te9WJm43HD/SgwTtLOGasUtIgwfF1OGqLwbXzM143ARmb2dMZqtQRJB+D9YaviU9tsDNyc+noqoWAGZT2Y2adm9iszG2Zm85nZzln+HpIGALcCBwALAAsCB+PXqZIMyGJZprPiRu8iM7uycRo3FjP72MyOxmcYOU7SJTH0ofsJw9fFSFoEuAE4CNjMzH7bK1VXUtWOowts6od7XJXwuQzKRunXRmyHvxjksxZeCaUchbJMhY+hm2hmv2+cqs3DzP4FrA68gvf9bZuxSkETCcPXhSQvb3dgHPAvfIhCVan3XcDceEJFIVau8Bx9GZTjgCtyKqRcDIwFlpf0sqT96lU2Q75YYlsl16nQNdoA2AvYPKdfcOv6VW0uZjbNzI7EuwNOlnSupDmz1itoPJHV2WWkB/UsYCVgKzN7KGOVsuId4L/4TBL5zBRarCaDMu2/W/3qtQ2lwqzP9P1TZZbp3RTOXO0IzGyMpFWB3+Le3x7pOwVdQnh8XYS8Sv0DeNLEGj1s9Egh3VFFNv+2lbq0OVfgiTb5TAKubbEubUPK/DwILyxwhaQjUgg36AKiSHWXIGkP4GTg/5nZBVnr0w6khur/AUcCCwNPAj8zs79nqlibIWkJ/N7ZDk9OuRrPxHwlU8XaBPnM75fjHvC3zez9jFUK6iQMX4eTsvJ+D3wFr7E5vswhPUcygAOBj2KgcnFSJiZm9knWurQbkgbhMz5sgD9nEzNWKaiDCHV2MJIWB+7CkzjWDKNXGHM+DKNXGjP7JIxeYdL9sz8ePr8rxvx1NmH4OpQ0EPtf+KDhr5vZuxmrFARdj5n9BfgycIKkk/q85KCziFBnh5HGpx0FHALsYWY9Ndt2ELQDqbLNBcBcwM5mNjljlYIqCI+vg5A0BM/C+xqwVhi9IMgGM3sbTwa6CXhAhScTDtqUMHwdgqQFgDuA94BNI+MuCLIlTXb7C7zc2/WStstap6AywvB1AJKG4TMq3ALsY2YfZ6xSEAQJM7se2Bo4Q1KlEwoHGRJ9fG2OpHWBq/DxZ2dlrU8QBIWRNBQvBH8F8JNemP2kUwnD18ZI2h44G/fybshanyAISiNpPuA6vBrOvhGdaU8i1NmmSDoIn5x0qzB6QdAZmNl/8QluZwNukjRXxioFBQjD12akWdJPwGeG3rBvRoAgCDoDM5sK7AhMAMakQhNBGxGGr41I5ccuADYC1jez5zJWKQiCGkhF0g8D/grcK2mVjFUKcohpidqEZPT+jk/nsoWZTctYpSAI6iCVyBsl6RXgFklfNbNxWesVhOFrC3KMHsBO0SEeBN2DmV0s6RO8zy+MXxsQoc6MyTN6O4fRax2SRkoyScPT56UkTcuZNXycpAGStpc0Pn1+UNKGWeueNZVeu5z915I0XdKO2WmdHWZ2OV5m8CZJI7LWp9cJjy9Dwuhlzm7A3cCuwLFp3bNmNlPDJOk24Fozs9RX83dgeCsVbUMqunYAkvoBvwFubpl2bYiZXZ7msg3PL2PC48uIMHrZIml2fG61/fDGuyhpNu6+Aa+z4ZO19izVXLvEofig7jeaqVcnEJ5fexAeXwaE0WsukhYBvgOsAEwEzixQPX8H4CYze0rSW5JWB94ChkrqexO/x8wOTuccCfwaWADYphXfIwuSd7Yz/h0/BC4qUAy94msnaVFgJLA5sFZrvkV7E55f9oThazFh9JqLpBXxyXnnzVl9iKSNzeyJnHW7ASen/y9Jn/9EkXCdmV0FXCVpY+B4YItm6J8lacqry3BD1cd+ko5OxZj7qObanQz80Mymp8Y+IIxf1kTJshaSJq28LH0Mo9cEJF1PYY9stJltk/aZF3gZD70Z0C/93QS4zsxWLiPjeXxaqP82UvesSbMLXFNg02fA0mb2YrXXLl2rPos3HzAV+I6ZXd2cb9FZpGSfU4GvmNmjWevTK0QfX4uQv96dhXvZYfSax5YVrN8RON/MljSzpcxsceB5YLFCB0oaln4/UlhvAPBmA3VuF4pdu1nwUCVUee3MbOm031LA5cBBYfRmkPr8DgVGS1oqW216hwh1to7j8D6nzcPoNZX3mTnM2ce7Of/vBpyQt/0K4MdFzvkNYO80FmsasIt1Z6jk/RLb+q5ftdcuKIOZXSZpYeBGSRuY2VtZ69TtRKizBUjaH/ghXoas5zPbmomkUcCRBTb9zsy+12p9OglJKwCP8/lI0BvAUlFNqLmke3cdYEsz+zBrfbqZMHxNRtLWwF+Ajczs6az16XYkDQYuBL6es/pKYM9ouMsjaU98VpDZ06pXgB3N7L7stOoNUnLRxXif6K4xn1/zCMPXRCStiU9MuW00HK0lVRQZDkwys0lZ69NJSJoDL5T+IXCXmX2SsUo9g6RBwC3AA2ZWKHIRNIAwfE1C0jJ4ZYvozA+CoGIkzQPcA/zZzE4ut39QPZHc0gRSyveNwC/D6AVBUA1m9pakrYB7JL1kZldkrVO3ER5fg0l9TLfilSt+kLU+QRB0JpJWw8OeO5jZPVnr002E4WsgaazX39LHPaJzOgiCepD0FeB8YF0zez5rfbqFGMDeWA4Dlgf2DaMXBEG9mNnN+LjJy1PiS9AAwuNrEJI2wNPm480sCIKGkSJJlwLvmtn+WevTDYTH1wAkLYjfmPuG0QuCoJGkKkH7ARtK2jdrfbqB8PjqRFJ/4B/AGDP7Wdb6BEHQnaTKOnfhBa0fzlqfTiY8vvr5FfAxXoszCIKgKZjZROBgvL9vnqz16WTC46sDSV8HTgLW6LYpaoIgaE8knQQsh1eEiiS6GgjDVyOSlsMrs2xjZg9krU8QBL1BmtfzDuCmvAmCgwoJw1cDkmYD7gP+ZGZnZK1PI5A0HXgsZ9UOwAbA93PWrQKsHrNFB71EkWfjFeBsYHW8Atb5ZvbrFuq0CPAA8C0zu6VVcruFMHw1IOkcYFbgm90yL5ukKWY2e4ntXwSuMbNlWqhWEGROoWdD0u7Adma2q6QhwBPApmb2Qgv12gTPJl/VzF5vldxuIJJbqkTS1/DZqA/uFqNXIbvhU6YEQQAGzJayugfjCW7vtVQBs3/iU56dmcb6BRUShq8KUvHpP+PhhVKzVXcigyWNS8tVBbbvQhi+oDcp9GxcDnwAvAq8CIzKaOb044Clgb0ykN2xhOGrjlOBy8zszqwVqQZJW0t6QNKnkp6WdGCBN8RpZjYiLSPzjl8HmGpmj7dO6yBoPpJWljRa0keS3pB0QoHSYIWejbWB6cAiuOE5Mk1F1lLM7CNgb2CUpMVbLb9TiWmJKkTSznhH9mpZ61INkrYArsdndQYYhs+wPQiodK6vXQlvL+gyJC2GDwifO62aH/ghsCQe2i/F7nhW5SfAG5LuAdYEnmuSukUxs3GSTgHOkfSVHuuCqYnw+CpA0kLAH/FklqlZ61MlRzHD6OXyI0n9yh0saRZgJ+CSaoRKmp4THhonaam0TMtZ1xUZsUF7UejeS+tXkTRW0gRJjwGHMMPo5bKrpGFlxLwIbC5nNmBdYFIDv0a1nADMBRyQoQ4dQ3h8ZUghwT8D55jZfVnrUwMrFFm/AP7Qlxt4vzHwsplV+yY7zcxG5K5IDdCz+es7gSIp7e/jfT1rAeeZ2SHNlNesjMEi321ZvDEdgCdufN/Mbm+G/CZQ6N7rD1wI7GVmj6b++rNKnGN54JkS2/8EnAs8jr9Ynmtm4+tTu3bM7FNJ3wTGSLqlhue1pwjDV5698Bj+zlkrUiOT8H6IfN4A3u77UGwoQ+rPXLcpmtVJkQZ7AeDMvl2AY82sULJOtRRqTGcDjgZWTksj+Zy8JlLou82NVwaZLGll4GZg0XoFlTLokpbAhwUca2aj6pWVx5eB8Wb2KICZvSmplIf2ZN8/hZ4NM5uCR0LaBjObKOlXwHmSNo2qLsUJw1eC1Fk8Cvhy6kTuRE4ANuPz4c4TzGx6rSdNtQK3BD4Dbjaz/FTuwZL6Bro/n5MUsLSkR/DU75+a2ZhadaBwg/0GsGZ6A14YeFTSdWb2aR1yCmJmHwB3VxAWawiSzsb7kcCN0Klm1pQasWb2SM7HCcAgSQMb8ByUMugnATeWOjhFYDYAhgKPFimmUOjeWw4wSTfjfXmX4H3d38VDhLlcamalvL125g/4C+Dh+PUMChCGrwjpATsLOKWTK5WY2T8kbYunPa8GPA/8Dqi5f03SHvi1GZxWvS9pTzO7Nme3Qg3cq8AS6W17DeBqSSsVMJo1k9cHOwgfb1WWlOiwCDCxyFCVYoa8JiQtiTe4E83s40rkmdm3c469GTivQlkCVsKf98cKvPCU+27fAB5p5sufpB3wxJAPSuwzL56otW7OuquB3czsw5xdC917/YEN8bD0VOA24CE8lP9bYAvgHXxc3DH1fp+sMLPpkr4F3CdptJk9WfagXsTMYimwADviIZlZs9alnRZgKeAT3KDkLlOB+XP2m1LBue7EvbNi21fGG6R5imyfDoxLy1U569fBvZQpwMgyOsyBTyDc9z3eB35QYL+i3wfYB/e+Krl+i+CNbp+814CdKpWHG/N/AVtUKG9VvB+qT94LwGZVfLeVgGeBoRXK64cbpk2BwZX8ZsBswFhgduBY4HtFzn1RgfvOgOPKfR88M/m8nM9H4/2WmT9TzViA/8NfjpS1Lu24ZK5AOy7AEODfeAmizPVppwVP9y7U+BjwnZz9CjU+8wP90v/L4PUOP2fUgAXxNPO+834I/LjAfiWNK57Y8y9gUIl9Li7yXXaqVFalhg8PN48tIGs6sFol8nAv76gKf6shwOQC8qYAC1cgazHgKWCDCuWNAJ7OkfMm8I1y3wvvTtg5/V/Q8AED8SSbQr/VsxXImBt4OF2T/sCteIH5zJ+pZix4ScUJeB9q5vq02xLDGQpzFDDWOmygeosYXGLbkDLHbgyMl/Qong15oBWudnE+sFHO54HAL+XTQFWM+fxlH1Ak8ST1UxZLWjqwGlkVMoLCiUKzAN8pd7Ckg4EvmNkJFcrbFli4wPrZgD3KyJoLuAH4kZndU4FuA9P+uf2d8wCXSFq2zOHrAL+V9AJwBPBjSfkZsv3xxrwQpe5JAMzsbeD3eGHnccDDZnZDueM6FfPxhYcBJ0kqe316jqwtb7stuCfyJrBY1rq044I3UsU8vuENOP8SJc5/Q96+hd7slwb6p/+XxD2e+YrIGlZC1mPlZKX1LwBv4V7Uy8CKJb7bV0vIu6qC7/Y87oH1hQoPLHMtDy0h77dlZP0Uf2kYl7MsUELW9iVkHV/uOuZsP5bioc5/Fjn/OVk/F+26AJcBx2StR7stkdzyeU7C6+69nLUi7YiZ3S/pD3jWWC7HmVkjBvDmZ9jlUmiwcT4bAkdJ+gTPOD3Iik8S/AIebi2Upj9TtqkVH+6xVAU69fEQHq4bUGDbTF5VIXlmtnQVsiDvOxTbVkTWL4Bq5nor9dtU8rtVwqH4PHS5s48/h/fXBYU5EnhE0l+thTNHtDsxLVEOkrYCTgFWts4dvtB0UpbgZsBIvH/qMqsgHFbhuQfgVTEWLLD5V2b2k0bIyZG3K/A3Zh7u8Rqwjpm92EhZSd7P8AzbXCYC61oDs1tz5P0F+Fbe6luAra2O4SwF5CyNJ8EUqhK0o5ld0SA5C+DfZygwHvirdV/B+IYi6af4PJpVdRV0M2H4EqmP4jHgCDMbnbU+vYykXXBjlNsH/TSwfgnvrR55GwAH48kc9wMnmdnkRstJsgR8HdgX925vS/LeLnlg7fJmwYsY74L3kV0DnNmMFztJv8b7x3O5GU8iaZiRDaojFd2eAHzXYtJaIAzf/5D0Q2BDM9s2a10CkLQWXndwQeBe4IxmGYegMSSjvg2eODMIT3Y53wqPUwxaiKTt8PGKq8TvEYYPAEmLAo/i4a1ns9YnCIKgkaSXkhuA263x5eA6jjB8gKS/4oWYG9p/FARB0C5IWg4fRzrczP6TtT5Z0vOGT9JwfLD0sGYkFwRBELQLkk7Dh5T8IGtdsiQMn3QxXrX911nrEgRB0ExSTdrx+HjT17LWJyt62vCl6VZuw+sQTslanyAIgmaTxuF+Zmb/l7UuWdHrhu8y4P7o7A2CoFdI03VNwMcrN2XYTrvTs4ZP0ghgNN63N7Xc/kEQBN2CpFF48fb8mqg9QS8bvquBO8zsD1nrEgRB0EpSBZyJ+KwgDa9Q1O70pOGTtCZwNe7tfVhu/yAIgm4jVdqZx8wOyFqXVtOrhu8GvNL/aVnrEgRBkAVpRvun8Mmgn89an1bSc4ZP0nrAJcByUYg6CIJeRtLP8SnY9s1al1bSi4ZvNHC1mZ2ZtS5BEARZkiYcfgZYq5e8vp4yfKlKy53AkuHtBUEQgKQTcVvwvax1aRW9Zvj+BLxpZj/LWpcgCIJ2QNJSwIPAUr1SyKNnDF9y6Z8DVjKzV7PWJwiCoF2QdCVwa68k/M1SfpeuYT9gdBi9IAiCz/EH4LA0cXHX0xNfUlI/4BD8xw2CIAhm5i7gQ2DLrBVpBT1h+IDtgNfM7IGsFQmCIGg3zPu8TgEOz1qXVtArhu8wwtsLgiAoxd+ANSQtn7UizabrDZ+kVYBlgSuy1iUIgqBdSeUbz8K7hbqars/qlHQO8KyZ/SprXRqFpOnAYzmrTge+m/4fBrwCTMMnnLwZ+H7OvqsAq5vZuBaoGgBOq+4AACAASURBVARBAap8hvcDzgZWB/oD5zdr4mxJiya9ljazd5shox3oasMnaT7gabw82X+y1qdRSJpiZrMX2XYn8D0ze7DAti8C15jZMk1WMQiCElTzDEvaHdjOzHaVNAR4AtjUzF5okm4XA/8ys5Oacf52oNtDnbviQxi6xujVyW7AxVkrEQRBVRgwm6T+wGDgY+C9Jso7A9iniefPnG43fHsCF2StRDVIGiLpSEn/kHSVpJGSlLfbYEnj0nJVFaffhTB8QdBUJA2VdIqkOySdKWnlArtV8wxfDnwAvAq8CIwys7carXcOY4C5Un5EV9I/awWahaRlgaWAWzNWpWIkDQJuA9bNWb0D8EvgpznrppnZiCrPvQ4w1cwer2Df/P6HHczsBUlrA6OABfG30LvxjNm1gWuAviK3V5rZz6vRLwjaiWqfATObKmlT3FtalhlOxabAXpK+bGZjcs5XzTO8NjAdWASYGxgj6VYze662b1caM/tM0kW44/CDZsjImq41fPiPdrGZfZq1IlWwBzMbvT6OknSGmb1cx7l3pXJv73MPpaQFgcuAXc1sbPJCvwF8Ie0yxsy+Vod+QQ61NLwZqNnNVPUMSBoAnAa8BOQPBxiE/2br1KjL7sBNZvYJ8Iake4A18RKMzeJC4BZJPzKz6U2UkwldGepMN+Se+I/XSWxUZH0/YP1aT5rKEO2Ez0NYKwcDfzWzseADXs3scjN7vY5z5uo4PSf0My4VzkXS2pLukvSkpEmSzk7h4O0ljU/7PihpwxbKHi5prKSPJDWrov00MxuRs7yQ0/D+0MyWB1YAbmLGy0fTqOEa7ZF+n/GS7pW0aqtk5xy3Vjp2x/q+/f8o9QzsDlwJrFXk2LUlDaxR7ovA5nJmw1+OJ9V4roowsyeAN4BNmiknK7rV41sX7wB+OGtFquS/JbbVk6CzMfByX2hE0up4COYt4KoCacuDJfUNd3jezEYCKwN/LSFjPUmPApPxjLQJVepYrZd5G3CtmVnqi/g7MLxKmbXKfgsP8e5Qo7xa+VzDi/f/9M0zuUjab2ncCyz1e1VLtdfoeWATM3tb0lbAmdTu8VQre6q8TOFv8OE85B0r/P5fAzcq16YxbLlU+wwsB8wKDCiy/V3gk5Lfsjh/As4FHgcEnGtm42s8VzVciDsQt7dAVmsxs65b8BvlJ1nrUYPeKwKf4iGs3GUS0K8B558F+HPeud8C1s/bb0qBY68Eti9y3jmA2dP/WwNP16BbIZk/B35ewbHrARPruC41yQaOxY18tfLmxsdmHQmsVmSf6cC4tFxV7jfIOW4NfOzXnA2+N+v5feYGXmmlbOAI/EXhPGDHnPWDcWOY+ww8BwytQGapZ+BU4D7gxwWeXwNObOTv0YoFf5F6GxiStS6NXrou1Jli7Tvj5Xc6CvPwwi7M7N09DGxrjYmz7wR8J2/d3MDF8lTpUkzAG9XPYWbvWZrHy8xGA7PKx1ACnrQjaSdJh6fwVH6WKhTOclsZeKiYQvKM10nADcC+Jfbrn+SupsLV56uWXSuSNgFewAckjwIelvSnAtckN9Q5ssJzz4dnMe9uVQ4+lrSopI0kLVBkl3qu0X7AjSVkzy9pP0kHSVq6XtnyQdgj8USTfL4PfDlv3dK4R1qOos8A8DIedv4NXh7xs7T+M9z4/rTwYe2LmU0GHgC2zVqXhpO15W3CW8q2eKJF5rrU8R0G4mGhlUhFBhp03ssp/DZqwHo5+xV6210Q+DewTs66PYGF0tJXDGFtPHzU93kFvMM/V9alwKx556/qDTtvv43xucQKbdsiT/6TeOWaumVTpceHh8EmF7n+IyvQ6XiKeDl4P/CteOivmntiEB6++yzp8QnecPerQJ9KrtFmwERg3iLbRwJTc67DZ/nXtFrZeAh03fT/eczs8T1W4hmYt4zMUs/ACnj4vT8wJH3nPYGFq/k92m0B9gauy1qPRi9d5/HRgWP38jGzj8zsfjObYOnuaxClfu9+ZXR6Hc8MHZWSCSbiyTjvATsCj6c+vlPwxteSF3M+sFje6XYGDqhA31Jv2Lm63QUMzfUyASQtgg+zyJW/HDA6NwmiHtlVsj6wcJFtO1Vw/KnAN+VDUwCQtKekhYATgPFmVm0C0y/wxq3P4+yP91/+vwqOLXmNUt/r2biBerPA9nnwfqTBuauBEyWtVofsNYFLJL2A35unSerrjy31DJRsD0s9A2Y2Eff4xgP/Av5sZhda58//eSWwkaT5s1akoWRteRv8djI73ok8T9a6tOOCN3CF3nQnAwOaIG/pIvKMPK+c6t+whzHDq1wdr22ovOO/X0L+brXKzvl8LNV5fJuX0OeSctcjrV8PH2D8JO5V/Bn3MAxPfujrF9yuAn1mAd4pos8zdf4+SwDPkNd/nHf8XiWux6/r/X3SuvOY2eP7ZRF5d2f5bLbzgncbfTdrPRq5dFtW5+bAA9bcqgadzEXANrjH1cdU4Jtm9nET5JW6v8ree2b2uqS+N+wF8DDYXfhb6DeBvSV9ghfz3cXSU5rDfBSn1LaSspOH9SCe1POZpCOAFc2sXBmpe/H+20JvzzNV77AidRzNMzoLDXsp1G9ajlmBOYtsK3l9ki6lfp9TgHlxbwvgUzNbM+8UNd8fZWSX4gQ8/LpezrrXqSwC0atcg7+knJ61Io2iq4pUSzoDeMrMfp+1Lu1KCj9ulpY3cU/jtSbKmoD3f+TzIzM7oRlyc+RvA1xfZPOq1pqU8JlIqf1XMHN47wJgHzP7rPBRTdXnPgoPM7jWzLZvsuyFca9t1gKbNzKzu5sktz+eC7Bmkn+pdfFMBPUiaW78Oi1oZtOy1qcRdI3hS43si8CWZtbUwZ1B5UhaF+/7yPUs/glsbU2uNpIyOK/FvdxczjSzzN7wU4O/KzAXnhAxpoC32ipdNgJuwZNc+ngXNzyPFT6qofK/g3sSuf1rvzezI5stO6gcSWOAX5lZ0ezcTqKbDN8XgauBYVk1IkFhUsf47nhix1jgemtRGaQ0vOVbwPb4GMlL8VJ2Lfeu2hVJK+IJLcviWY+nWJPqQBaRvzwefh+IZxDe3yrZQWVIOgpY1MwOzVqXRtBNhq+rfpggCIJ2IWXoXkWXOBbdNJxha2B01koEQRB0IY/h41DzC3B3JF1h+FLn6wjgzoxVCYIg6DqSlzcadzA6nq4wfHgJoru6JeMoCIKgDQnD12ZsjddrDIIgCJrDbcA6kpo+DVaz6XjDl1LWt6JEEdwgCIKgPswL0Y/F6992NB1v+IBVgTfN7IWsFQmCIOhybuLzs1t0HN1g+NYH7slaiSAIgh7gHmYu99aRdIvhuzdrJYIgCHqAR4Bhnd7P1w2Gbz087hwEQRA0kVTMfhw+72bH0tGGL1XJnwufoiUIgiBoPmPp8HBnRxs+/OLfH3UXgyAIWsZYvIupY+kGwxf9e0EQBK1jLLBuGkrWkXSs4ono3wuCIGghZvYqPnXVclnrUisda/jSdDOrAf/KWpcgCIIeo6P7+TrW8OFFqZ8zs/eyViQIgqDH6Oh+vk42fBHmDIIgyIbw+DJiLSBmag6CIGg9jwLLSJota0VqoZMN3wrAhKyVCIIg6DXM7BPgGTp0YtqONHwpjXZ5YFLWugRBEPQoE3EHpOPoSMMHLAa8Z2bvZq1IEARBjzIJGJ61ErXQqYZvOOHtBUEQZEnHenz9s1YgF0kLAtsCXwReByYDdxaYa28F/KIHQRAE2VDQ45M0K96OLw4sAnwIXAc8ZGbWUg2LkLnHJ2kBSd+XdA9ebHpL4CVgDnxm9X9IGph3WHh8QRAE2fIkMFRSvgP1Q+BYYCjwDjAYuAh4SdKfJG3YUi0LoCwNcEpSuRd4DjgfuMPMPsrb5xrgPjP7dc66O4FfmNmtLVQ3CIIgyEHSc8BXzOzp9HkJ4GFgzfxInaThwA7A/wO+amYPt1jd/5F1qPNA4FNgzxIzLPwf8C9JF5jZy2ndcCLUGQRBkDWT8K6np9Pn3wF/LNA9hZlNAk6Q9CpwpqR1zezTlmmaQ2ahTkmLAMcB3yk1rZCZPQecDpyYjpsbGIL3/wVBEATZ8b8EF0lfAtYEflvmmPOB94BDmqtacbL0+E4BzjCzJyrY99fAREmbAh8Bk9qlkzQIgqCHmQSsnxJaTgH+z8ymlTrAzEzSgcC9kq40sxdboWgumXh8krYFVgV+Vcn+ZjYVOBK/sMOBp5qnXTZImlfSuLS8JumV9P80SU/kbHtP0hFZ6xsEQXMp0SaMk/RDSRMkPS7pYkmDMlJzEl5M5GDgZeCaSg4ys6eAPwCnSlLz1CtMy5NbJM2Olxrb18xuq+I4AbcCHwBPmNlRTVIxcyQdC0wxs1F56/sBrwDrmNm/s9AtCILWk9smSFoUuBtY0cymSfo7MNrMzstAr2WAO/Dup41SP16lxw4EHgGONrMrmqRiQbLw+I7Dx+ZVbPTA3WPgMGAL4P1mKNYBfAl4thFGT9JCki6R9GzyKEdLWk7S9Jy3ymsboHMQdB0lnp8lJN0iaWJav1STVOgPDE5DCbLMeXgdWBQ4rxqjB5Ay+A8A/iBpjmYoV4wsDN+WeMiyasxsAj525KNy+7Ybkr4o6XxJj0j6u6R1azjNrsDFDdBFwFX4C8hQM1sR+DGwIDDNzEakZbt6ZRWQXajB2ETSQ8nYTkjx/6ZTovG6SdI7kq5vhR7V6JaVPrkU0W1tSWPT7zde0i4Z6rJc2jZHCg+e2mCZpZ6f84ETzWwFYG3gjRLnmUvSLyQ9IOkOSd+qJOxnZq8Ao4AXgVeBd83slvq/WU1MA6bjYcuqMbMxuPFcsZFKlSOL5JYPgX51HP8+8GCDdGkJktYC/okP5ASfRPfrkr5mZjdVeI4BwHbAjxqg0mbAJ2Z2Rt8KMxuX5DTg9IXJaTD+ama7pnUjgDmB9c3soxQKf1zStWbWtLfYErosiGcQD8HfRltOGd0y7d8u8xvubWZPyzO2H5J0s5m9k4EufdfpePy5azQFnx9JKwL9zewfad2UErrPBtyFV6nqY1O8bTi8lHB5Zvv2wNL4APHLJO1pZhfW9nVqx8w+k/RvoJ7pifrjdqFlZOHxfQjU0xG7EP6W00n8nBlGr49+eLZqpWwFPGxmr5faKb3l/lTSXentd5cCb5ErAw8VOcUgSQ9Kuk/SDlXoVwkFGwwz+2dO4YKBtOa+LKbLmBSGzzKcXuzFZMucMPQrks5tF93Sb/h0+jwZ93Tmz0iXMZLWwA1g1Z6QpOUlnSHp3hSlWT1vl2LPz3LAO5KuTJGdE+X98oXYm5mNXh+HVhAe3QJ43sz+k6YHupJsZ0N/FVi4juMH0WLDl4XH9xH1G77XGqRLqyg2U/EISYPMrJIffTfKhDklDQHuBFbLWb1V+lxpMtASZjZZ3ml9u6THzOzZcgdJGgx8D/hGWnUlMCpl5PZR1OBKWhy4ARgGfL9eb0/SssCOuCG93szyowSljH9TkTQP8HVgLuD2AhUsCupmZj8DfiZpTmAM0NAQXtJtXjykvghwH540Mb2cbnnnWBsYAJS9b8qc56t4AYsl8SSIX5nZY+V0kVeE+h2wF94vXo3MVfFr+4W0aj1gV0lbV1Apqj+wEf68vQhcCuwDnFNg32JtgvAQ6Qsl5LwIrJue92n4d8wyCvYa3i7XSk8Yvpo9vhQemBUf/NhJTMZDQfm8BXxc7uB0g29J+dDb3sxs9Pr4vqRTcyrfTMCNwufoMzhm9py8NNxqlGnAUkNzHTM3MqsCm0raolSBghy5LwGrpDDZ1ZIuL+fdltBnP+BMZniOx0j6TTtkAsvHol6D16LtW3c6cHAlY1OT934RcJKZNdRwp5D8zcDcOatvTyH5kmOzcs6xMHAB8M1KfvcS59kDyA3dLQ9sJ2mDvrB8CQ7CDfZLNYTuj2eG0etjVnxQdp/nV+z5eRl4JBXdQNLVwLoUNnylXuxKvvSZ2f2SLsdLg32KvxScWeqYJtNxhg8za+kCXAbsVOOxQ3EXv+V61/mdDwKswHJ8g+VcUESOATvm7CfgfmD/nHVrAZsAA9Pn+fAyRCtWIPfLJeR+NWe/LwF3VXC+c3P1rfIaLIS/TBTSZb1KdcH7W65v8O8zAG/UCuk2shLd8KzoM5pwjwp4rIhuP6xQtznwxrim5zvnPLMA/y6iy+XldMFfDF7Evab/4i/KJ1Qo+80S9/KQCp6fR4H5c+7jg4vIGYY39vkyxgGzNPr3beaC5x1UdH2LHP8OMFcrde60Pr5ODHOCl1w7Fujr7P4QOBlvxBpJ0Qwycq6b+d02Eu8zelbShKQfwIOSHsXH5pxglVXWWavCbbcDAyXt37dC0lryrM7B6fPcwAZ49m4tbIW/oRcit8+yqC41yq2E9SneF7JTBbodg3v+hzVBt2Xw0GEhKr1uVwHnm9lldeoyP7BEkW1l7yfgTDNbwsyWwsPv51vl3n6xZ+hdUjZ5iedncpJ3m6THcAN5VqGTmdkzeLLa83nf52tWh6ecER3n8XVUqJPOTGzpe1COkzQKWAp42Zoze/zZeKOY/7s+js+CkavTZGDnAuco1OFejpcq2WZmJmkkcLKko/B74QXgauCPkgxvLEbZzH051TC9xLb/NSgldDlC0hi8QtDskl4G9jOzm2vUJ5dSL5r/21ZCtyF439u/UgjvWvN+v0ZQ73W7D9gYmFfSPmn3fax8WLIQ7+CFKgplClZyP9VT2eh0Cqfmn2k5fZ0lnp+ngVUqEWRmt0gaBiyLD05/pQZ924FXqdHwpdD9AFo9RC0Dt/iPwKE1HnswcHqrde6kBX+LfIUZoZO7gaWaLHM2vH8jP2wzGZi9xd9/XmBqAV0MWD3j32YQ7lEU0m2XjHUT8EAR3Q7PQJ8Ti+iyc5PlzoKXUpyW5H0C/BkYkOXv084LngcwrsZjBwEftlrnTgt1zk7vVm2pCDO7FvcqVwOGmdmGVmCKkAbL/AAPweV6lWOBLazEWKYm6fIm8E1mfoM04CjLcP4vAPPs3b3xRjWXC/C+78wwb4X2wV+acrkSOK3lCvmA8JOZca3+g/eX/b2ZQs3sMzP7MR6SXhNYxMwOMLOySWg9zPt421wLrU9sIZtanccDH5vZ8TUcewzQzxoX3gkajKSFAMws075YSQvifVMDgRusgiEZrSJdo13x4Qy3AXdbqx/EIqS+1h3whv8+YGyWuqVM7vmBV8zHrAVthqTF8MnCF6vh2IVwb7GePsKqyaqPb0iNxw6i84Yy9BRZG7w+zIdC/DlrPQqRrtHJWetRCPNhC3WXxWsUKZrwQdZ6BCWpJ4qXicfXaaHOTC5SEARBUJSOa9PD8AVBEAT10HFtehi+IAiCoGbM7FMA+RRJ1RKGrwLC8AVBELQftbbrYfgqIAxfEARB+xGGrwxh+IIgCLqLMHxlCMMXBEHQXYThK0MYviAIgu5iKD4jfLWE4auAqifXCoIgCFpCLfakpwzf4DqOrWf29iAIgqDxPAs8V8Nxg2j1zAxkY/gGUsGs40WYRhi+IAiCdqNWz+1jfFqilpKF4Zsfr7ReC+HxBUEQtB+1Gr7/4jahpWRh+OYjDF8QBEE3MYjPT7dVCf/BbUJLycrj+2+Nx4bhC4IgaD/C4ytDeHxBEARdQl+Nzr6anVXSMx7ffITHFwRB0C0MpPYhCW8C80hqqS2K5JYgCIKgHmoei2dmnwBTgLkaqlEZwuMLgiAI6qHeQegt7+eL5JYgCIKgHhph+Fraz9dpyS0fAHM0UJcgCIKgPr6At8210vIEl5YavtSBOQ/wVo2neA1YsHEaBUEQBHWyEN4210rXhzrnBt5LHZq18Bp+kYMgCIL2oF7D190eH/UltgC8Shi+IAiCdiI8vjLUM5QB4HVgIUkxPVEQBEF7sBDulNRKeHylMLMpwHQiwSUIgqBdWJjw+EpSz1CGPqKfLwiCoH1oRKiz6z2+ekKdEP18QRAE7UQjklu62uOrN7kFwuMLgiBoJ8LjK0O9yS3gF3jhBugSBEEQ1IGkIfgM6u/WcZr3gIGSWlaVKzy+IAiCoFYWAl4zM6v1BOnYlnp9nejxTQYWbYAuQRAEQX0sSn1DGfpo6ZCGTvT4ngKWa4AuQRAEQX0sj7fJ9dLSIQ2dmNU5CRgeg9jrR9JCki6R9KykJySNlrScpGmSxqV1Z/RNEilpelo/TtK1rZAraUlJD6X1EyQd2LgrEHQy1d6/6Zg5JL0i6dRWyZW0hKRbJE1M25aq/9u3DcPxNrleWjuI3cxasuBTV3wEqAHneh1YpFW6t3IB5gXGpeU14JWcz5b+Pg5cBgzB37jG5SzvAUdUIEfAWODAnHUjgI2Ax9Pn/sBdwNfT5ykN+H5VycU7zgem9bMDLzTqt8f7Jy4BngWeAEbj0YRp6Vo+AZwBzJL2vwl4B7g+6/sk66Waa5d+37HABGA8sEur76Ocff4A/A04tVVygTuBLXPu4SFlZFTVBqRj/i9d38eBi4FBLboPbgC2b8B5TgUOa9X920qPbz7gv5a+ZZ1MAlZowHnaDjN708xGmNkIvOE4KefzB+n/lYGP8YfvyZztawBTgasqELUZ8ImZnZEjexzwUs7nT4F7gWEN+4JVyjWzj83so7RpIA2KUqSIwVXAnWY21MxWBH6Mz/7xbLqeqwArAjukw04E9mqE/E6mhms3FdjbzFYCvgqcLKneGbervn8lrZF0vKVVciWtCPQ3s3+kbVPMbGopAdW2AZIWBQ4D1kzr+wG71vEdq2E4MLEB5+na5JZGJLb0MZEuNXxVMIbPG6Qv4Q3PvyXNKelrkraUNKDA8SsDD5USkFKVvwQ8llYNkvSgpPsk7VDkmFlS2KdYAlLVciUtLmk83rj8xswmlzq+QqpuOM3sNuD9BsguSy1hvBZS7cvLU2b2dFo/GXiDCvpzJM0maUVJhUoUVnUfpev0O+D7FchdQdJISYXamGrv3+WAdyRdKekRSSdK6ldOhwrJbQP6A4Ml9ccjQY14RkoiaTCwCPBcA07X0kHsLff4GnSuSfibRschaZiksyQ9KukGSV+t4Rz9ga2YYZD62BW4WNJeeHjkOvzt9nlJ61UhYqikccA9wA1mdmNav4SZrQnsjr+1D83T60t4R/eTwMuS7pC0RL1yzewlM1sFf8i/KansnIyShkhaRVKxh6kWw98SavRGGyl/VkkrS1qsyC41XztJa+Ph62dLHCtJx+FdGhOA1yWNqsJgFLqPDgJGm9lLxQ6SNFjSlXiY9krgiWSwBtchtz8eBv0esBawDHC4pFPSC8ytknZOv3nF5LYBZvYKMAp4Ec+wfNfM6vFqK2U54Ln0klMvrR3E3qqYKrAbcHGDzvUV4LZW6V5AvgEX5Hzuj7+xXJ8+D8f7AT4Cvpez37L4JLyWt3yriJxj846fzoxY/x+BATnbBuA3z4Zpv3wZbwCDc/b/EnBXAZlLkfoqylyD84Adcz4vjffv5MsdT+oja5Dcc3PlFtguvJF5N8n/NB0zOG+/w/AQUiE9+vqpHgGOzdu+KU3u4wM2r+QaAScAPwB+nnNfvAKcW4fsnfHGs+/3uxFYoEHXbmH8pWjdMjocVuA+MuDoWu8j4CLcMLyQnpP3gBPy9vldEbkn1iF3XfwFpu/zwXjUIF/Gj4pci2Mp0wbg85zejntMswJXA3uWucbl2rA98Gd3PO65r1rgHLsAVzTwnr+jmc/VTPJaJshv5j826FxLAq+0SvcC8qekB3tw+rxVuhH7bpoF8Le7X+bdtH8p8mC9CsxaQE7+TV80uQTYHvfuflVEhjFzJ7+A+4H9c9atBWxS5AGemxlJJvMBTwMr5mw/voTczeqQu1jOdZ4b9yi/WOI67F5EhzPy9qvJANMAw4f3wWwGjCTPqOQ8K8UMS18CxRDgAWCrnO1z4g3VGjXqtRaFX5rurPfa4TOqPAzsVIEeTxX5DV8nJcdVex/lnX8fCiS34AaxkNz/1HH/9gMeBeZPnx8tIuMDYM4Cxx9LmTYA2Ak4J+fz3sBpZa5BuTZsfWDunG33F9HtF/U8CznnWqXc79bIpdWhzkb18b0EzCVpzgadrxZuBLZJ/++GZ1IBYGZvmNkDQP5M8+sUOddCQDUhwUL06fCFEvv8r6/E/G4bCWyZ+pEm4Ddysb6BFYAHJT0K3IG/LT+Rs32REnL/V2KuRrn3J7n/BEaZWanQ40FF1u8jabacz7fjZZL271shaS38papppGSHJ5P8K4GXJB1ZxSkKhoNTqOwi3GCWDEOW4AAKd39skvTuo6prl/qYrwLON7PLKtCj2L20AG5IarmPKqHYs1Pzc2Nm0/EIxG2SHqN4P9YQ4Is16v0isG4K7wt/Makk4aRUG3avmb2dPt6Hv4Dm06ihDNDFwxlOBw5q4PkeBtZukq7zABsDSxfZPgV/Q7kcH6YxjgKeAJ9/W/sHhd/2PqbGt720fgjwJv7Gv10RGdPxPrpm/b77F5FreIJDq+6zZ0vosWjevosAf0/HTMBTs5eluNcyBn9ApwEvA1+pUrdZ8IaikG6b5uxXi0d1HHlebQ3X7oYS1+5LtV47YE/8JTB32M2IEnrcWkSHB5p871xfRG7DQtvA+SWu8TIF9q+0DTgu3VuPAxfg0ZENgRWK7F9RG5b2/R5wdoH1j1JjdKHAuQake2SWRpyvrLxWCElf7C/AoQ0830UU6Rur45xKN9CHOTfjNcAc+TdN+vsg8C08vPi5m6bATbt9kRv+rAZ+h1mAKwrI+GmTf9/BzBhnlLuUDLk0QY8Lilzj51v1UJXQbb0Sjd65efdhNeG0r+H9MAPq1O8nRXSbBszT4uuU31/8CWksXBPlrsjnw53/JSek3wAZ61I4nNxI4/odZvRxGx4dyH/pq7QN2wz3HufNW98fH6Yye4N0nh1vd1sz/rAVQtIX+xowtoHnOwI4vcE67lPkwb8gb7++m+ZnuKf1xSI3zbHkGL607kDca+h7mM8hL/GiAd+jbxzPBcCZa6/iggAAIABJREFU5HgTTf6N58T7+h7AB+1+mxYbGzzTLD+B6DMq6FtqgW5fLnJ/GXB53r7VeFR34Ekbfd7Uz2vUb2687zZftx9ncK1GABfi/VCXAuu0SO7CwDH44PxjgIWbIGNnPGLQd29eTupPa8C5Ny5yf91LTvGQStow3CN8FliugJzVgQkNvCb7Ate07P5qmSB/Q3gZWLlB51sHGNdgHe8pctN8Qo7Xl3PTLAYcnv6f6aZJ644lz/Cl9QPwiisNudlj+dz1HYqH1h9IjcrGWeuU9JqDwhl9BhyQtX5Jx/nxbNH78T6gb2StUzcuqT1cjpT00sDzFot4WG7bW64Nw3MOngHWLyLnYAqEP+vQeyywbauuf39ahJl9KulcvC/o8Aac8hFgWUlfMLNGDSou1rnaH/dm3stdaWYv4yWQZkLSQngIYQ7gM0lH4OGS99JxH+MJDkETMLNnge9mrUc+ZvaepMNxLz+Xf+LDQzLHzP4DHJW1Ht2O+di3RhR3zmfeEts+174Va8NwT3Be4LQ0xPBT8zG8fayHRxrqRtLKwOL4i1ZL6EsNbo0wL876ILCYmX3YgPPdA/zMvKJG3Ug6Cw/P5dPn7n/WCDlBb5NKZ+0DzIVnSF6UXoaCoC4kHQX8usCmKXg/33sFttUi5zngazZzZnet5zoZeN/Mjq5fswplttLwAUi6GU9rvqgB5zoRr1Lwi/o1A0lL4qm7uRPdTgdGmtl1jZARBEHQLNIQr3uAlfI2HWpmNc9IkSdjQTyDdN56nQH5rOsv4Rn6zzdCv0poWagzh7Pw+HDdhg+PC+/XgPMAYF7jcnVSwVd8fMxpVvu4qCAIgpZhZu9K2gBvYzfBE73OblRULLEecF+DImBfBx5ppdGDbDy+AbiF39BS4do6zrUwPm5l/ghDBkEQNB9Jv8Fnifh5A851B+5cVFLYoGG0vLJ76ss4n8J9adWe61U84SRmZA+CIGgN6+PDI+pC0rJ4SPaaujWqkiymNAE4G6+yX2i6nIpIFdz3w1PWq5l5IAiCIKiB1GavBiwhaYE6T7cfnu/R8sSuTAyfmT2Jp/NvW8vxaUqOM4BD8AG7YfiCIAiaz6r4/HtLAvcmr61qJM2KZzaf3TjVKicrjw88yaXqcGcqNHw1XrdwY+BmvCZdEARB0Fw2wCtwHQP8BhhT5VyffWwLPGVmjSpyXRVZGr4rgLXTEIKKSGm0d+Ilv76WBq6PA+avcsLTIAiCoHq+ik9/hpmdhZcau1ZStRMifxt3fjIhM8NnZtOAvwFHShpYbn9Jy+PDF24A9jWzT9J5pgM34XNGBUEQBE0gRds2wGeZ4f+3d97hclXVG34/QiCEEOkgNSJFIEDoVVBCQEGkiXT5iYIgIIKgAiKCikpHEAFBupRQpCqKROmdAKEZMBTpSA2hhvX7Y+1LDpOZuXPvnZk9Zb3Pc5577zlnzvnOnnP3t+vaAGZ2LZ73nixprxqvswoecvLSRuishZw1PoDj8GCnL0g6X9KWJWumASBpLTys0y/N7Gc2/RyMa5m2rlQQBEFQf9bHl4YqDd14N26Ie0k6UtInfCUNRFxR0i8kPYJ3VR1oZlOapryEps/jKyvC5+Ntjk9mXA1fj+syfH2s0cCpwE5m9tcKn58Tj04/bz1CoQVBEASfRNLvgSfM7OgKx+fCpyY8gzeBrojn6Vviq1Bciufrd+Wed90SxlckJd6mwFZ45IG38Kjd9/byuZuBn5vZdY1XGQRB0D2kld2fwhdfrri6u6RZ8BUiNsFjHPeY3QNlWuqy0XLGV0TScFzjGzWcexAwn5nVY+WHIAiCIJFWULgKXyW+qmmkps75zey5pojrB7n7+KpiZm/WYnqJa4CNG6knCIKgS9kYuLaWWpuZfdTKpgctbnx95AFgFkkRviwIgqC+bIJXLjqCjjG+VBK5lqj1BUEQ1A1Js+Oj7/+ZWUrd6BjjS4TxBUEQ1JcxwE05px/Um04zvn8Aq6cSShAEQTBwNqODmjmhw4wvhTD7O/C13FqCIAjaHUnDgK8ATV0vr9F0lPElzgN2zC0iCIKgA9gMuMXMXsotpJ50ovFdC4yMoNVBEAQDZke8MtFRdJzxpUUNxwLb59YSBEHQrqTVcNYgwwrpjabjjC9xHrBTCrMTBEEQ9J3tgCs7aTRnD51qfLcCQ4FRuYUEQRC0KR3ZzAkdanxpMnsMcgmCIOgHkpYGFgBuyK2lEXSk8SXOB7aTNCi3kCAIgjZjB+BPaaHvjqNjjc/MHgWexRdPDIIgCGogra6wAx3azAkdbHyJ84CdcosIgiBoI9YG3gbuzy2kUbT0enwDRdK8wGPA4mb2v9x6giAIWh1J5wH3mdkxubU0io42PgBJZwGPmtmvc2sJgiBoZSR9GngYX3D2tdx6GkU3GN+KwJX4F/lBbj3tjKSpwIPAjMAjwM5mNkXSk8BbwFTgQzNbJZ/KIKidKu/07MDpwEjAgF3M7LZ8SpuDpMOBuc3su7m1NJJO7+PDzO4DJgGb59bSAbxjZqPMbCTwPrB74dgX07G6mJ6kqZLGS5ogaaykoZKGSLpT0v2SHpJ0WD3uFbQW5b77wrFBku6TdHWdblfpnT4B+KuZfQ5YATfFjkbSzMBuwIm5tTSajje+xAnAPrlFdBg3AYs38PrlMqT3gPXNbAU8OMGXJK3RQA1BHqoVsPahcSZ0E7C4pOHAusAZ4GEQzez1Bt2zldgWuN/MOt7ku8X4rgAWlrRybiHNoEJtaam0r2d7U9L3y3x2eG/rGUqaEfgy3kQE3hT0N0n3SNqt/k/kGZI5k9O+wWnr7Lb64OMClqSFgE3wJsiakDSzpHnTEP1q5xXf6cWAl4EzU+3ydEmz9lV4pZqrpH1Ti8UESRdIGtLXa9ebFN5xH7yS0PF0hfGZ2YfA7+ieWt90JWYzeyztGwWsDEwBLu/5gKQRkv4CvAG8JmmcpM+VXHcWSeOBu4GnSSViYG0zWwnPOPaUtG41cXK2knRhyhB2qBRooNRkU1PXeOAl4O9mdkdfEqYWqmRYf5T0kqQJ9b5nrRqaRYXC08LpvXgkZdx9/n+SNFLSSZKulHSIpLmrnFtawDoe+CHwUQ33GSzpN8ArwIvAJEk7lDm13Ds9I7AS8HszWxEf2v/jmh9yGtP9H0paEPgesEraPwivaeVmHWAY8NfcQpqCmXXFBswJvAbMn1tLE551cuH33YGTS45viK+x1fP3zMBEvPZU3J4FZit33Sr3/hmwfy/nnFTmXheQBlulc6YC49N2IjBTyTVmB8YBIxucfucD+6Xf18UzxAlN/g4/1pDpHTof2A/4NLBS2jcb8G9gmT5c80u4ARS/96eABUrOm+67xxdDPTkd/wJwdS/3OrrMO2bAlys9Z2Hf/MCThb8/D1wzwDTcHTgZWBB4JuVHMwJXAxs287utoHUssHduHc3auqLGB2BmrwIXAd/JrWUgSJo/NZX8QtKY1ERR6dzSEnMP2+JG08OmlO+vWwDYphc9s0qared33FQr1ogkjQL2LHNoW+CLhb97SsujzGxv8+WmPsa8z+WfeGbaSD5uajOzG4FXG3y/ihok7V5oqp4kaVwz729mz5vZvQBm9hbe17ZgLRdITY2/xZuniywCHFyyr9x3vzbwVfkI4guB9eXzzcrdayiwRwUp+/am1cxeAJ6RtFTaNRof4l+8xyKSDpD0c0mfr/X/0MyexU35aeB54A0z+1tvmhqJfO3S9YGzcupoKrmdt5kbsAz+ss2cW0s/9W8ATOaTJdhLgRlLzqtYW8JLz68A8xX27U/50rEBvyycV650vBge4eF+4CHg4F6eYd8q9/p5L/eaB5g9/T4LniF/pY9pOAT4FvBH4FfAkmXOmZx+zoj3D+9RODaCJtb4KmgYnJ59035eexZ89N4fgV8Cn+3L/Qvp8DQwvMZ7LlLle3+k3L2rXOsLVKnx9XKvibXcCx88dTfwAPBnYI7CsS3xgVbF655BocWi0v8hMAce+Hme9D3+Gdix0e9TL+n5G+C4nBqa/sy5BWT4kq8DvpVbRz90D8abHsv9M+9Scm7FjAPYDPhbyb7RVTKKrer8HP9X5V4/qPYMwPLAfSkzmgD8tI/3HgbcWXLP9ygxz3IZVuHYCAZgfHiz8i+A5/B+1quAZcucV03DycBh/bz/p1IaFtPgXWBMH+4/DLgH2LIP9509XbPc935rre9vOv4FqhvfYLxfr9y9Lhrg+zsMeL3CtTfr7TmArYEzCn9/g5KuiGZu6X14mTKFn07esgvI8EWvjc/rmym3lj7qXrOKYVxZcm4147sQ+GbJvhmAf5S57p3A4Do/x6fwvtbSe02hpK+nAWl4YIX0+2/xOXtJvxEMzPjOLXP/V4GFavkO8YLDNcAM/bz/4RXS4IniNavcfzBeeOxznyNwcYV7170givepld7nbWCFAV73K1X+D8/s7TsEVsdbRoYCAs4mY98acChwdq7759q6po+vBzO7BY/f+c3cWvpIteVBalo6JPV9jAEuK+43s4+Ar+I1kX8Dj+P9EGOsztFuzOyNdK//Fna/jNcsn6vnvcpQqT9wQWDZBt8bSZ+h/BqRcwC9RspI03H2x5vGeh3ZWIFKabAYsEQv9xfepPeImR3bj3vvDlxf+PtD4Ci8ybWumNkpeP/0rfi7djmwjpkNNPDygP4PzUchXwLci/e9zwCcNkBN/ULSnMDeeGGoq+j4kGXlkLQ6PoppCTN7L7eeWkjD/ScCnylzeHszu6DM/pZF0mBgDXw4923N+B4kXYsPMijHkmY2MZ032cyGlfn8BXgz29x4U9qhZnZG6XlV7r8xXlsrxxVmtnnh3Ok0SDoT2AifygFwt5l9u9b7p2uMw5+hHIuY2TNV7r8O3rf4INOmFBxkZtf2UcMywML4ZOkX+vLZ3EiaBe/bLDcNYyPLPFClL0j6BT7KvU/vUCfQlcYHIA959FczOym3llqRRym5GpirsPt04DsDqAF0DZK2A/5U5tAdZtbwCDCSFscLL+X4jZn1Z65YXzXswrT5l0X+aWZfLLM/KEHSBniryWyF3UcBP7I2yVDT/MnHgJXN7MnMcppONxvfSvjAgsXN7J3cemolTR3YAje/f1kaXh70TmqqOwqfk9Yz/PxRfHDLE03ScCHTTxF5A+97eqoJ958Bj86xV2H3BGATM3u60ffvFCTNgY/unA0PpPBQZkl9Ik3uH25mlaZ9dDRda3wAki4HbjSz43JrCZqHpBH4YKEX8cJDTX2kdbr3ELwvdRd8oM84fML/+GZpSDo+C6yGT++5MVoMugdJ8+FzMFfoadruNrrd+JbHR6gtbmZv59YTdBeS1C5NY0HnIOlYfO7v93JryUVXGx+ApIuBu8zsqNxagiAIGomkBfCm7ZFNGEXdsoTxScvikRQWNw/DFARB0JFIOhH4wMz2y60lJ11vfAAp5t8TZnZobi1BEASNIPXr3okHFn8xt56chPHxcZDWe4FVzWxSbj1BEAT1RtKV+JzZX+XWkpuui9xSjjSM+zigP9EogiAIWpoUPGFpIo8DwviKHAMsJ2mj3EKCIAjqhaSZ8bmb+7RLpKpGE8aXMLN38SVzfitpptx6giAI6sS+eHzVPoWW62Sij69AiuxxNR6+KaY3BEHQ1khaCF8rc7VmRSdqB8L4SpC0BHAbsHw3z3MJgqD9SYHVHzezQ3JraSXC+Mog6Qg8Un25JWSCIAhaHknrAecAS5vZlNx6WokwvjJIGobHstvezG7KrScIgqAvSJoRn6J1uJldkltPqxGDW8pgZpOBA4CT0gsUBEHQTuyBL/B8aW4hrUjU+CqQBrr8HV9y5De59QRBENRCWn3kLmA9M3s4r5rWJIyvCoUXaH0zezCvmiAIguqk9RavxxfZPjK3nlYlmjqrkFYm/jFwdsztC4KgDdgTGIIH5AgqEDW+XijM7bs7glgHQdCqSFoSuAVYy8wm5tbTyoTx1UBaw2o8sLGZ3Z1bTxAEQRFJg4CbgfPN7KTcelqdaOqsgTSRfR/gHElDcusJgiAoYX9gCnBybiHtQNT4aiQ1eV4MPGlmB+TWEwRBACBpOXwx7VXM7KncetqBML4+IGke4AFgazO7ObeeIAi6mzTo7nbgJDP7Y2497UI0dfYBM3sZnxh6VoruEgRBkJODgeeAM3MLaSeixtcPJJ0NfGhm38qtJQiC7kTS2sBlwCgzez63nnYianz9Y09gTUlhfEEQNB1J8wMXAd8M0+s7YXz9IMXy3Ar4taSVcusJpkfSVEnjJU2QNFbS0LR/IUlXSJoo6QlJJ/QEJ5C0WvrMeEn3S9oi71O0J/1J+8JnF5E0WdL+edS3Pil+8IXAGbG4bP8I4+snZvYIXvO7RNKcufUE0/GOmY0ys5HA+8DuaWTuZcCfzWwJYElgGPDL9JkJ+Mi4UcCXgFMjSHm/6E/a93Ac8Jemqm0/jgDeAw7PLaRdCeMbAGZ2MXAFcG6KkRe0JjcBiwPrA++a2ZkAZjYV2BfYRdJQM5tiZh+mzwwBogN84NSU9gCSNgf+AzyUSWvLI2lL4OvADikNg34QmfXA+SEwHB9d1ZX0s1lxh0Kz4nhJH0ka1Yd7zi1pvRRIvNp5MwJfBh4ElgXuKR43szeBp/HMGUmrS3oonb97wQiDhKRZJa0jaWSqyVU6r+a0lzQr8CPgsAZp7s87OljS2ZIelPSIpAMboa0Pz7AkcCo+neqVnFranTC+AWJmHwDbAHtI2jC3nkz0uWnLzM5PnxkF7AQInyZSS8Z0JD6E+5/AJEmvS3pA0ikFTbNIGg/cjWeuZ6R7lKvFfbzfzO4ws2WBVYEDI1LPJ5H0TeBZvCb3IHCHpEVLTutP2h8GHJf6z0vv2a8+Q0nLS7otFWQA1uhj8+vWwMxmthywMvCd3gpajSIVDC4FfmJmd+XQ0FGYWWx12ID1gBeARXNryfDskwu/746HTRoN3Fhy3nDgf8DQkv1HAO8X/j4f2A/PFO/ER64BDMKD8FqZ7fRKmgr7NqhVUzo2Du/zy5GmU/H4sBOAsT36gIXw5vWJwBPACcBMTdK0RoW0v5c0Naq/aY8b6ZNpex14FdirzPtV7d04Azgq/T0jHmxihZ5rAIP68o4C2wFXpWvNBfwbmDPDu6D03GcX0zm2/m9R46sTZvYv4GhgrKSZc+upJ5KWk7S/pD0kzVflvD41KxbYBig2KVbrFxpa4fY7SZqll0f5BzBU0jeS3kH48i1nmdkUSZ/pGcySajFL4RlxDgYyQKRRVJq+syLQ2+jmqmlvZp83sxFmNgI4HjjCygdbnu7dSN/ZxsAzeDp9CtgQeMDM7u/5oJlN7eM7egnwNvB82ne0mb3ay3M2gj2BkcAelpwwGBhhfPXlGPwf5A/V+j7aBTlH4iXno/BS8iRJm5ac2mvTlqRZJH0FmB2YrbB/dTy47kfp76oZE1BpBO1MeAm+IinT2ALYWtJEvAT/LnBQOmUd4P70LJcD37XW6EupaYCIpNMLfaYvS6r3Mlpz9/NYtbQ/WNK6kraVtFi1a5R7N+Qjqm8DrgQOxQsC9wKrACbpOkn34qbb1+bX1fCa9wLAZ4Af9Kax3kgaDfwU2MrMpjTz3h1N7ipnp214jeR24Oe5tdThWUZTvmnrdWBY4byqTVvAF4GXC59/G/hGOnYcbjw9TXvjgRNxI9sHOLbkuudU0PQfvMQ/PHe61ZCui+ADOX4FjKFM81VPmuLNbFfgofK+h/eDlZ57H7B84e9FgUepc7M78P0Kaf8OMEc/rrcwcH/hOh8BvwVmKDmv4ruBF8bKaRoPTMINeWi6xuhK72hhX7Gp83fAToVjfwS+3sT3ZHngJeALud/ZTtuyC+jEDZgHeBzYLbeWAT7H7ytkKgZsXjivnPEJL13vBrxW5vNTgaWB/wKLVbhGuYxp+ZRBFq/1PrARPtglS59cH9J0U7ymU9R/Ean/qXBeTQWBdO54YLn0+xC872uDBmgflky29Lvcr5/Xu6HCu7VLyXkV341kDOWu8SFwduH894ADKryjPYWwQcAfgGPS3z/CY2AKmBV4mEIBo8HvyUJ4QW7b3O9sJ27ZBXTqhjdNPQ9sklvLAJ7hlCrGt0XhvOkyprR/YbypstI1zgJur3SNKhnTqcCv8cEnfwBWwM3zWTIMPuhDes4CvFIhLbYvObdfg3NSmv64gc8wG3AA8Fc8esiYfl5noSrvxbga0qLn3XizwjU+wJs8h+K15g/L/S+md/Qqpg0WOhEfyQlu9GPxeYUPU2KcDUzjT+HNuU25Xzdu2QV08gasjpdIW7oWUkX/hhUylTepsUkR2LVKBndM4bxq5lkpY9oqZUr3p0xu09xp1ktaVGo6NuCiknP7UhDoqaHsCVya+zlrTIulqqTFXb2lReHdeKrCNS4BdkzvxwTgyNzPXGO6zITXhE8kRnA2Lp1zC+j0DdgMn3O2WJVz5sdLz0+kkuW1+Ii9d/BmrPuBW4Gl0vlz4bWdyfg6XI3SLrzPpZihvId3tNd6jRF4s125zKlftYV23fApL5Uy+/NLzu1PQWASPmikp4l099zPXCUtZkj6y6VFzf3jeB/e/SWfnwgsnPsZ+5EmAs7DB1YNKnO8r/nEGLzF5cH0c/3cz9gqWyxL1AQk7YkPTFjLzP5Xckz4y3q2mZ2S9o3Cm5R+bz6cHUnfSZ/fOU1mXREf4jzSzPZqsP5V8diVk4GxZvbfPn7+IKYfcn8usLN10QsoaTA+CGehMoc3M7MrmywpK5LG4CZenP7zALCemb3eh+vMhBcwR+LGf5mZvVNPrc1A0hH4QLDRVjKCs5/5xIrAi2b2nKSRwHVmtmATH6lliQC8TcDMfidpYeBKSRuU/FN+Efig52VO548vEyFiOD5IBDN7G7hZUul8uIZgHimi39EizOwISTcC2+KZ3FXA1d1kegBm9oGkbfGh98VpGcfjadJVmNnfU4a8Cz5l4HbgnNJMv4brvI/3xY2tv8rmIGl34Gu4aZV7/v7kE/cV9j8EDJE0s5m9V0/t7UgYXwNJpbQt8Ym/c+Av5SWSNjcPdQZeSi2dq9bDZ9Pco9nwTvrVGyy5YZjZzcDNuXXkxsxuSZnV5vicxhvMrGuDMpvZ40ybR9mVyINz/wqv7V4l6Xp89O5rhdMGmk9sBdwXpueE8TWWg4Gfl+xbFLhY0tcL5leJJ8xjWSJpG+A0vMkxaGPM7C28qTfociRthvfrzQqsm3avAWwpaY30rvRG1XxC0rLAb/DBagERuaVhSJoL+EmZQ7Pi89fOT30+D+EBcHvjSqb9YwRB0OYk0zsdn3tZyjLAtwt/9yufkLQQPljmG2b2RP/VdhZhfI1jJT7ZaV/kcdwAz8cn4c4sadeeg2kwyaIln1kHH80VBEGbk0zvNHzQ16AKp61V+P0G+phPSJoduAY40MxuqZP0jiCaOhvHC1WOPYeP8rwUN7+tgaMl/RiP6vEkHh6qp+1eeHSSj0uAkp7E+wxnSn0EG5rZw/V/jCAI6knB9Dbp5dSP8xAzM0lbAMf3IZ/YCw+kcYikQ9K+Dc3spXo9S7sS0xkaRBrYciNeAivyEbCamd0jX+vtUjx25Q419PkFQdDGFE3PzO5O+cQd+PqPRT4EVjazB5qtsRuIps4GkYbqfw34W2H3C8B2ZnZPOuddfLTVrEzr8wuCoAMpNT34OJ/YHG/K7OE5PBh2mF6DiBpfE0hz+GYHHi1Xq4uaXxB0NuVMr8w5i+BxOsvmE0H9CONrEQrm9w5ufjHfJgg6AElb4csnVTS9oLlEU2eLUGj2NOA6SXNklhQEwQCR9D083u2Xw/RahzC+FiKZ3zb4SgM3p6aPIAjaDEkzSDoaX0B4bTO7N7emYBphfC2GmX1kZvvhE1tvTYFogyBoE1K3xQV46LC1zezJvIqCUsL4WhQzOw7YF/ibpAg1FARtgKQ58ZHcwpfdejWzpKAMYXwtjJmNxYNcnyNp59x6giCojKRF8UDsdwHbpq6LoAUJ42tx0qoGXwB+JumQNOE16AOSFpJ0haSJkp6QdIKkmSTNJWmcpMmSTsqts92pks5jJN0j6cH0c/3cWutNWvvuFuBUM/uBmX2UW1NQmTC+NsDMHgXWxCe6niYpQs3VSCooXAb82cyWwFesHobHSHwXOATYP5/CzqCXdH4F2NTMlgN2psNWppC0Ed68uY+ZnZBbT9A7YXxtgpm9AKyHL9j5D0nzZ5bULqwPvGtmZwKY2VS873QX/9Nuxg0wGBjV0vkxM3sunffxgqh5ZNYPOT8EzgY2N7NLc2sKaiOMr40ws8nAV4FxwN2SSuOAdh0p81lK0rKSyr3Py1KygKeZvQk8jQfwDWpE0vySVpI0a5nDtaZzRyyIKulTeA13K2DVWP2gvQjjazPMbKqZ/QzYFbhU0r7d2u8naTlgPPAoMAF4TNLapafhQQGm+3iF/UEJkoZJugCPIXkP8Lyk/UpPo5d0LiyI+p0Gym046b27C0+Pdc3smcySgj4SxtemmNlf8HlCOwAXSpots6SmImkocB2wfGH34sC1kuYt7HsIWKXks8OBhYn1DWvlJGBb3MQAZgOOkbR14Zyq6dwpC6JK2hEPKH24me3Z7jXXbiWMr41JE2PXAd4A7pS0TF5FTeWrwKfL7B8ObF/4+x/AUEnfAJA0CDgGOMvMpjRcZZuTFjPdocLhPQq/V0xnYCbafEFUSTNL+h3wU2B9Mzsvt6ag/4TxtTlm9q6Z7QYcCfxL0ja5NTWJ+aoc+3jgT1r2ZQtga0kTgX/jg1kOgo8X9D0W+D9J/+2ywkMtzEHlBatrTefigqjj0zZvuQu2Iml1lX/hA8tWNbMHM0sKBkisztBBpLlElwBXAT80s/czS2oYklYF7qxw+KtmdlUz9XQqaerMk8CCZQ6fbma7NldRc5E0BjgHOA44yiLD7AiixtdBmNl9eD/LCLzpc4W8ihqHmd0F/KnMoeuBa5sNKZdHAAAHkUlEQVQsp+5UmgzebB1m9iFwANMPXHkZOKLZepqFpKGSTgDOBLY3syPD9DqHML4Ow8xew5ucjgeul3RQB0943xkfIXgDcCOwHz5RempWVQOkl8ngTcfMLsCjB10C3I4vs7OKmU3KoafRSFoTuA+YG1jezMZllhTUmWjq7GDSskZn4AM+dk4RYIIWR9Jo4FAzW7ewbzgwCbgCWCntXhA4ycwOa77KziNNqv8Z8E1gz5iQ3rlEja+DMbOngY3wyBI3S/p+hUneQWtRbTL48WY2CtgM+B8+ajIYIKl//C7gc3gtL0yvg4lMsMNJ6/udDKwBfA24QdJnMsvqWiQNkvQDSQ9JelbSuWW+j6qTwdN6b2OBvczsqUZr7mQkDZZ0CD4n9ChgSzN7KbOsoMGE8XUJZvY4Huvzanzgy27dGvElMycBRwPL4MPjd8QXHC5Oz+ht0v0pwGVmdn1TFHcoaerKrcDawEpmdm4MYOkOoo+vC0n/8OfgE9/3NrOHM0vqCtJ8sCcpX+A8LIWi6xncchfwWzM7J00GPwV4E/gPPoF6q6aI7kBS1J8fAXsCBwOnheF1F1Hj60KS0a0B/Bmf9H5sCrobNJaRVP6fG9XzSy+TwfcHlitMBN+9wZo7hhTQfEvgYbwvb0UzOzVMr/uIGl+XkyJoHAFsDBwInBuLaDYGSZ8DHqlw+DgzKw38HNQJSUvj0zA+jbdyxBSFLiZqfF2Omb1kZt/GF7ndE7hF0sqZZXUkaTrJ1WUOTQF+32Q5XYGk4ZKOxud5Xo3X8sL0upwwvgAAM7sTb/78A3CNpFMlzZ1ZVieyPT63sieq/z3ARmY2MZ+kzkPSDClg9qPAnMBIMzvBzD7ILC1oAaKpM5iOFJH/MGC79PPUFLoqqBNpsvQQM3sjt5ZOQ9JKwIn4qhB7m9ntmSUFLUbU+ILpMLPXzWwfYDS+wvQjknZMowuDOmBm74Xp1RdJy0oai8dqPRNYPUwvKEcYX1CRtPzKaDwe5h7ABEnbRPSXoJWQtJSkPwHj8GkgnzWz02OQVlCJaOoMaiLNLdsQOBwYChwKXB5DwYNcSPosvjDsxviyQSea2Vt5VQXtQBhf0CeSAW6CGyC4AV4dBhg0C0kjgJ/gI5FPxOOXRrNxUDNhfEG/SAa4OT745V285H1dGGDQKFLkm4OAr+PTP441s1fzqgrakTC+YECk/r6t8OVcPgBOAC4ws3dz6go6B0mrAd/DWxpOw1dCfyWvqqCdCeML6kIywA2BffD14v4AnGxmz2UVFrQlkgbjBap98GgrJwFnpIWWg2BAhPEFdSeF5tobn6z9F+AEM7sjr6qgHZA0D7Ar8F3gcbwF4Uozm5pVWNBRhPEFDSNNhN8FN8GX8EzsEjN7P6uwoOWQtDxeu9sSuBxfmWJ8XlVBpxLGFzScNPF9UzxjWwpvBj0vwnR1N5JmxQdI7QosgQ9YOdXMXs4qLOh4wviCppJK9t8CtsXXljsPuDgyu+5A0ox4UIQd8cLQrfjakJdFS0DQLML4giykwQsbADvho/VuxE3wSjN7J6e2oL6kqS8r4ma3HfAM/l1fZGYv5tQWdCdhfEF2JM2GL7y6I7AqvkDuucC/YlBD+5Immm+Pf69DcLM738weyygrCML4gtZC0gJ4M+iOwLzAFXjQ4XFmNiWntqA6qWY3Eg8htim+yvlYvBBzWwQ3CFqFML6gZZG0DPAVvCl0JeAm4BrgWjOblFNb4KQBKqNxs9sYmEr6joDro98uaEXC+IK2IE2N2BDPXL8MvMq0DPbmyGCbh6TF8e9hE2At4E78e7gWeDRqdkGrE8YXtB0pSszKTMt8lwRuwAfI3AbcF0ZYH1Lz5aLAmrjJbQgMx03uGrxW92Y+hUHQd8L4grZH0nzAGGBtPINeAhiPD5W/De9fej6fwvZB0hC8ULEWnpZrpkM9aXkDMD7WugvamTC+oONIo0RXZVotZQ3gLaZl3rcDD5vZ29lEtgCp5jwCWIVpRjcSeJhUYEjbU9F8GXQSYXxBx5Oa65ZkWg1m9fT3S8CjwCMlP1/upIxe0ix4LXhpfKRlz88lgVeAe5lmcnfH6Nmg0wnjC7qSFEZtBNObwdKAMc0EH8UnXL8APJ9+vtVKxihpJmA+YP60LYAbXc/zLIBHySk1+cfMbHIOzUGQkzC+ICiQaofz4IbRY4YL4Evj9BjLINwAi2bYs72OL8xby/YRMDM+ubu3bVZ8XmNRR882HK+9FnU8jpvbI8AkM/ugrgkVBG1MGF8Q9BFJw/hkDevThZ+zMc2sZqG6mQ2idpOcArzIJ82tZ/tfDDYJgtoJ4wuCTEhSKzWZBkG3EMYXBEEQdBUz5BYQBEEQBM0kjC8IgiDoKsL4giAIgq4ijC8IgiDoKsL4giAIgq4ijC8IgiDoKsL4giAIgq4ijC8IgiDoKsL4giAIgq4ijC8IgiDoKsL4giAIgq4ijC8IgiDoKsL4giAIgq4ijC8IgiDoKsL4giAIgq4ijC8IgiDoKsL4giAIgq4ijC8IgiDoKsL4giAIgq4ijC8IgiDoKsL4giAIgq4ijC8IgiDoKsL4giAIgq4ijC8IgiDoKv4fmRuKDUMtJ/UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:119: RuntimeWarning: This filename (source_space/src_space.fif) does not conform to MNE naming conventions. All source space files should end with -src.fif, -src.fif.gz, _src.fif, _src.fif.gz, -fwd.fif, -fwd.fif.gz, _fwd.fif, _fwd.fif.gz, -inv.fif, -inv.fif.gz, _inv.fif or _inv.fif.gz\n",
      "  src = mne.read_source_spaces('source_space/src_space.fif')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Distance information added...\n",
      "    [done]\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    Distance information added...\n",
      "    [done]\n",
      "    2 source spaces read\n",
      "Loading surfaces...\n",
      "Three-layer model surfaces loaded.\n",
      "\n",
      "Loading the solution matrix...\n",
      "\n",
      "Loaded linear_collocation BEM solution from bem/fsaverage_bem.fif\n"
     ]
    }
   ],
   "source": [
    "montage, src, bem = MP.init_exp_for_sl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_pp = MP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading epochs/S20_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/S20_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/N5_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/N5_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "750 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/S21_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/S21_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/S12_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/S12_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/T6_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/T6_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (-1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 2 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 199 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 199 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/S11_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/S11_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/S17_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/S17_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/N7_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/N7_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "750 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/N2_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/N2_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "760 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (-1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 10 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/S19_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/S19_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/N3_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/N3_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "750 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/N12_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/N12_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "750 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (-1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 1 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 149 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/S2_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/S2_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "996 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 199 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 199 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 198 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/S10_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/S10_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/S16_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/S16_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/S18_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/S18_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/S3_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/S3_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/T5_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/T5_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/N9_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/N9_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "750 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/S1_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/S1_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "828 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 169 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 161 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 168 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 167 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 163 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/T4_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/T4_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (-1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 1 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 199 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/S15_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/S15_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/T2_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/T2_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/S13_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/S13_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/T8_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/T8_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/S8_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/S8_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/T1_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/T1_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/N14_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/N14_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "750 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/S9_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/S9_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/T3_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/T3_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/T12_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/T12_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/T14_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/T14_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/T10_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/T10_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/S7_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/S7_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/S14_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/S14_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/T11_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/T11_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/N8_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/N8_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "750 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/N11_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/N11_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "750 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/S5_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/S5_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/S6_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/S6_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/N6_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/N6_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "750 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/T9_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/T9_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/N1_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/N1_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "750 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/T13_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/T13_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/N10_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/N10_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "750 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/S4_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/S4_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1000 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 200 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/N13_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/N13_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "750 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/N4_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/N4_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "750 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/N15_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/N15_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "750 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 150 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "Reading epochs/T7_epoch.fif ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:40: DeprecationWarning: Setting a montage using anything rather than DigMontage is deprecated and will raise an error in v0.20. Please use ``read_dig_fif``, ``read_dig_egi``, ``read_dig_polhemus_isotrak``, or ``read_dig_captrack`` ``read_dig_hpts``, ``read_dig_captrack`` or ``read_custom_montage`` to read a digitization based on your needs instead; or ``make_standard_montage`` to create ``DigMontage`` based on template; or ``make_dig_montage`` to create a ``DigMontage`` out of np.arrays.\n",
      "  self.info = mne.create_info(montage.ch_names, sfreq, ch_types='eeg', montage=montage)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:66: RuntimeWarning: This filename (epochs/T7_epoch.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
      "  self.epochs = mne.read_epochs(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "1282 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Not setting metadata\n",
      "0 projection items activated\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (1)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 260 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (2)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 255 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (3)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 252 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (4)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 256 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n",
      "    Read a total of 1 projection items:\n",
      "        Average EEG reference (1 x 64) active\n",
      "    Found the data of interest:\n",
      "        t =    -200.00 ...     798.00 ms (5)\n",
      "        0 CTF compensation matrices available\n",
      "        nave = 259 - aspect type = 100\n",
      "Projections have already been applied. Setting proj attribute to True.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "data = list(filter(lambda x : x.endswith('.mat'), os.listdir('Data/')))\n",
    "data = ['Data/'+ d for d in data]\n",
    "re.split(r'[./]', data[1])[1]\n",
    "evokeds, epochs = mne_pp.generate_ERPs(data, montage, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = epochs['N10_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Info | 17 non-empty fields\n",
       "    bads : list | 0 items\n",
       "    ch_names : list | Fp1, Fpz, Fp2, AF3, AF4, F7, F5, F3, F1, ...\n",
       "    chs : list | 64 items (EEG: 64)\n",
       "    comps : list | 0 items\n",
       "    custom_ref_applied : bool | False\n",
       "    dev_head_t : Transform | 3 items\n",
       "    dig : Digitization | 64 items (64 EEG)\n",
       "    events : list | 0 items\n",
       "    highpass : float | 0.0 Hz\n",
       "    hpi_meas : list | 0 items\n",
       "    hpi_results : list | 0 items\n",
       "    lowpass : float | 250.0 Hz\n",
       "    meas_date : NoneType | unspecified\n",
       "    nchan : int | 64\n",
       "    proc_history : list | 0 items\n",
       "    projs : list | 0 items\n",
       "    sfreq : float | 500.0 Hz\n",
       "    acq_pars : NoneType\n",
       "    acq_stim : NoneType\n",
       "    ctf_head_t : NoneType\n",
       "    description : NoneType\n",
       "    dev_ctf_t : NoneType\n",
       "    device_info : NoneType\n",
       "    experimenter : NoneType\n",
       "    file_id : NoneType\n",
       "    gantry_angle : NoneType\n",
       "    helium_info : NoneType\n",
       "    hpi_subsystem : NoneType\n",
       "    kit_system_id : NoneType\n",
       "    line_freq : NoneType\n",
       "    meas_id : NoneType\n",
       "    proj_id : NoneType\n",
       "    proj_name : NoneType\n",
       "    subject_info : NoneType\n",
       "    utc_offset : NoneType\n",
       "    xplotter_layout : NoneType\n",
       ">"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mne_pp.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source space          : <SourceSpaces: [<surface (lh), n_vertices=163842, n_used=4098, coordinate_frame=MRI (surface RAS)>, <surface (rh), n_vertices=163842, n_used=4098, coordinate_frame=MRI (surface RAS)>]>\n",
      "MRI -> head transform : instance of Transform\n",
      "Measurement data      : instance of Info\n",
      "Conductor model   : instance of ConductorModel\n",
      "Accurate field computations\n",
      "Do computations in head coordinates\n",
      "Free source orientations\n",
      "\n",
      "Read 2 source spaces a total of 8196 active source locations\n",
      "\n",
      "Coordinate transformation: MRI (surface RAS) -> head\n",
      "     0.999310  0.009985 -0.035787      -3.17 mm\n",
      "     0.012759  0.812405  0.582954       6.86 mm\n",
      "     0.034894 -0.583008  0.811716      28.88 mm\n",
      "     0.000000  0.000000  0.000000       1.00\n",
      "\n",
      "Read  64 EEG channels from info\n",
      "Head coordinate coil definitions created.\n",
      "Source spaces are now in head coordinates.\n",
      "\n",
      "Employing the head->MRI coordinate transform with the BEM model.\n",
      "BEM model instance of ConductorModel is now set up\n",
      "\n",
      "Source spaces are in head coordinates.\n",
      "Checking that the sources are inside the surface (will take a few...)\n",
      "    Skipping interior check for 999 sources that fit inside a sphere of radius   47.7 mm\n",
      "    Skipping solid angle check for 0 points using Qhull\n",
      "    Skipping interior check for 906 sources that fit inside a sphere of radius   47.7 mm\n",
      "    Skipping solid angle check for 0 points using Qhull\n",
      "\n",
      "Computing EEG at 8196 source locations (free orientations)...\n",
      "\n",
      "Finished.\n",
      "Computing data rank from raw with rank=None\n",
      "    Using tolerance 0.0001 (2.2e-16 eps * 64 dim * 7.4e+09  max singular value)\n",
      "    Estimated rank (eeg): 64\n",
      "    EEG: rank 64 computed from 64 data channels with 0 projectors\n",
      "Reducing data rank from 64 -> 64\n",
      "Estimating covariance using SHRUNK\n",
      "Done.\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Using cross-validation to select the best estimator.\n",
      "Number of samples used : 75750\n",
      "log-likelihood on unseen data (descending order):\n",
      "   shrunk: -832.243\n",
      "   empirical: -1810.482\n",
      "selecting best estimator: shrunk\n",
      "[done]\n",
      "Converting forward solution to surface orientation\n",
      "    Average patch normals will be employed in the rotation to the local surface coordinates....\n",
      "    Converting to surface-based source orientations...\n",
      "    [done]\n",
      "Computing inverse operator with 64 channels.\n",
      "    64 out of 64 channels remain after picking\n",
      "Selected 64 channels\n",
      "Creating the depth weighting matrix...\n",
      "    64 EEG channels\n",
      "    limit = 8197/8196 = 3.381871\n",
      "    scale = 60961.1 exp = 0.8\n",
      "Applying loose dipole orientations. Loose value of 0.2.\n",
      "Whitening the forward solution.\n",
      "Computing data rank from covariance with rank=None\n",
      "    Using tolerance 0.1 (2.2e-16 eps * 64 dim * 7.2e+12  max singular value)\n",
      "    Estimated rank (eeg): 64\n",
      "    EEG: rank 64 computed from 64 data channels with 0 projectors\n",
      "    Setting small EEG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing SVD of whitened and weighted lead field matrix.\n",
      "    largest singular value = 4.67789\n",
      "    scaling factor to adjust the trace = 1.26921e+11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kam/CP Project/MNE_Pipeline.py:147: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  return mne.minimum_norm.make_inverse_operator(info=info, noise_cov=cov, forward=fwd, loose=loose, depth=depth)\n",
      "/home/kam/CP Project/MNE_Pipeline.py:147: RuntimeWarning: No average EEG reference present in info[\"projs\"], covariance may be adversely affected. Consider recomputing covariance using with an average eeg reference projector added.\n",
      "  return mne.minimum_norm.make_inverse_operator(info=info, noise_cov=cov, forward=fwd, loose=loose, depth=depth)\n"
     ]
    }
   ],
   "source": [
    "fwd = mne_pp.compute_forward_sol(mne_pp.info, src, bem)\n",
    "cov = mne_pp.compute_covariance_mat(epoch)\n",
    "inv = mne_pp.create_inverse_operator(mne_pp.info, cov, fwd, 0.2, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "snr = 1.\n",
    "lambda2 = 1. / snr ** 2\n",
    "stc_epochs = mne.minimum_norm.apply_inverse_epochs(epoch, inv, lambda2, method='sLORETA', pick_ori='normal', \n",
    "                                                   return_generator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading labels from parcellation...\n",
      "   read 35 labels from /home/kam/mne_data/MNE-fsaverage-data/fsaverage/label/lh.aparc.annot\n",
      "   read 34 labels from /home/kam/mne_data/MNE-fsaverage-data/fsaverage/label/rh.aparc.annot\n",
      "Preparing the inverse operator for use...\n",
      "    Scaled noise and source covariance from nave = 1 to nave = 1\n",
      "    Created the regularized inverter\n",
      "    The projection vectors do not apply to these channels.\n",
      "    Created the whitener using a noise covariance matrix with rank 64 (0 small eigenvalues omitted)\n",
      "    Computing noise-normalization factors (sLORETA)...\n",
      "[done]\n",
      "Picked 64 channels from the data\n",
      "Computing inverse...\n",
      "    Eigenleads need to be weighted ...\n",
      "Processing epoch : 1 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 2 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 3 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 4 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 5 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 6 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 7 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 8 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 9 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 10 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 11 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 12 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 13 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 14 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 15 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 16 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 17 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 18 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 19 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 20 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 21 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 22 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 23 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 24 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 25 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 26 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 27 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 28 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 29 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 30 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 31 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 32 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 33 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 34 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 35 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 36 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 37 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 38 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 39 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 40 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 41 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 42 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 43 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 44 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 45 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 46 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 47 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 48 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 49 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 50 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 51 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 52 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 53 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 54 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 55 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 56 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 57 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 58 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 59 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 60 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 61 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 62 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 63 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 64 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 65 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 66 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 67 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 68 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 69 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 70 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 71 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 72 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 73 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 74 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 75 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 76 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 77 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 78 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 79 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 80 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 81 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 82 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 83 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 84 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 85 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 86 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 87 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 88 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 89 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 90 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch : 91 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 92 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 93 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 94 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 95 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 96 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 97 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 98 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 99 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 100 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 101 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 102 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 103 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 104 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 105 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 106 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 107 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 108 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 109 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 110 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 111 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 112 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 113 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 114 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 115 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 116 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 117 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 118 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 119 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 120 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 121 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 122 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 123 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 124 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 125 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 126 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 127 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 128 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 129 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 130 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 131 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 132 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 133 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 134 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 135 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 136 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 137 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 138 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 139 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 140 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 141 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 142 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 143 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 144 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 145 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 146 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 147 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 148 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 149 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 150 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 151 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 152 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 153 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 154 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 155 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 156 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 157 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 158 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 159 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 160 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 161 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 162 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 163 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 164 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 165 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 166 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 167 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 168 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 169 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 170 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 171 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 172 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 173 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 174 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 175 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 176 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 177 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 178 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 179 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 180 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 181 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 182 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 183 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 184 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 185 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 186 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 187 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch : 188 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 189 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 190 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 191 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 192 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 193 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 194 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 195 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 196 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 197 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 198 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 199 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 200 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 201 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 202 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 203 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 204 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 205 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 206 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 207 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 208 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 209 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 210 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 211 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 212 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 213 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 214 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 215 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 216 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 217 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 218 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 219 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 220 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 221 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 222 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 223 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 224 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 225 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 226 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 227 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 228 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 229 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 230 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 231 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 232 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 233 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 234 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 235 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 236 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 237 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 238 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 239 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 240 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 241 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 242 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 243 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 244 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 245 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 246 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 247 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 248 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 249 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 250 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 251 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 252 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 253 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 254 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 255 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 256 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 257 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 258 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 259 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 260 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 261 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 262 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 263 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 264 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 265 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 266 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 267 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 268 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 269 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 270 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 271 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 272 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 273 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 274 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 275 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 276 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 277 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 278 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 279 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 280 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 281 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 282 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 283 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 284 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch : 285 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 286 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 287 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 288 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 289 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 290 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 291 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 292 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 293 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 294 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 295 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 296 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 297 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 298 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 299 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 300 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 301 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 302 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 303 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 304 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 305 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 306 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 307 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 308 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 309 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 310 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 311 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 312 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 313 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 314 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 315 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 316 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 317 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 318 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 319 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 320 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 321 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 322 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 323 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 324 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 325 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 326 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 327 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 328 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 329 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 330 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 331 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 332 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 333 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 334 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 335 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 336 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 337 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 338 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 339 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 340 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 341 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 342 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 343 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 344 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 345 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 346 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 347 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 348 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 349 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 350 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 351 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 352 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 353 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 354 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 355 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 356 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 357 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 358 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 359 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 360 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 361 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 362 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 363 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 364 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 365 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 366 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 367 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 368 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 369 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 370 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 371 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 372 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 373 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 374 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 375 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 376 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 377 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 378 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 379 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 380 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 381 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch : 382 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 383 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 384 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 385 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 386 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 387 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 388 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 389 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 390 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 391 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 392 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 393 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 394 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 395 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 396 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 397 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 398 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 399 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 400 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 401 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 402 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 403 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 404 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 405 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 406 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 407 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 408 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 409 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 410 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 411 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 412 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 413 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 414 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 415 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 416 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 417 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 418 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 419 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 420 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 421 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 422 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 423 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 424 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 425 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 426 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 427 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 428 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 429 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 430 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 431 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 432 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 433 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 434 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 435 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 436 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 437 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 438 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 439 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 440 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 441 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 442 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 443 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 444 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 445 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 446 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 447 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 448 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 449 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 450 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 451 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 452 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 453 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 454 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 455 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 456 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 457 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 458 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 459 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 460 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 461 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 462 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 463 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 464 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 465 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 466 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 467 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 468 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 469 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 470 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 471 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 472 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 473 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 474 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 475 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 476 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 477 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 478 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch : 479 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 480 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 481 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 482 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 483 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 484 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 485 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 486 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 487 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 488 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 489 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 490 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 491 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 492 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 493 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 494 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 495 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 496 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 497 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 498 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 499 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 500 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 501 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 502 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 503 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 504 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 505 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 506 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 507 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 508 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 509 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 510 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 511 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 512 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 513 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 514 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 515 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 516 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 517 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 518 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 519 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 520 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 521 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 522 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 523 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 524 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 525 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 526 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 527 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 528 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 529 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 530 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 531 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 532 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 533 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 534 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 535 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 536 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 537 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 538 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 539 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 540 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 541 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 542 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 543 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 544 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 545 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 546 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 547 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 548 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 549 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 550 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 551 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 552 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 553 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 554 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 555 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 556 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 557 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 558 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 559 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 560 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 561 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 562 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 563 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 564 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 565 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 566 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 567 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 568 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 569 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 570 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 571 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 572 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 573 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 574 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 575 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch : 576 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 577 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 578 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 579 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 580 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 581 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 582 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 583 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 584 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 585 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 586 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 587 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 588 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 589 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 590 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 591 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 592 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 593 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 594 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 595 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 596 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 597 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 598 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 599 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 600 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 601 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 602 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 603 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 604 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 605 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 606 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 607 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 608 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 609 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 610 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 611 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 612 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 613 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 614 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 615 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 616 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 617 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 618 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 619 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 620 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 621 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 622 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 623 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 624 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 625 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 626 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 627 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 628 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 629 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 630 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 631 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 632 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 633 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 634 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 635 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 636 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 637 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 638 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 639 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 640 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 641 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 642 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 643 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 644 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 645 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 646 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 647 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 648 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 649 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 650 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 651 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 652 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 653 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 654 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 655 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 656 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 657 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 658 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 659 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 660 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 661 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 662 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 663 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 664 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 665 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 666 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 667 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 668 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 669 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 670 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 671 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 672 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch : 673 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 674 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 675 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 676 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 677 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 678 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 679 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 680 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 681 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 682 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 683 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 684 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 685 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 686 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 687 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 688 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 689 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 690 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 691 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 692 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 693 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 694 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 695 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 696 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 697 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 698 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 699 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 700 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 701 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 702 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 703 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 704 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 705 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 706 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 707 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 708 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 709 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 710 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 711 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 712 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 713 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 714 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 715 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 716 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 717 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 718 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 719 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 720 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 721 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 722 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 723 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 724 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 725 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 726 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 727 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 728 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 729 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 730 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 731 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 732 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 733 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 734 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 735 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 736 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 737 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 738 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 739 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 740 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 741 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 742 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 743 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 744 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 745 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 746 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 747 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 748 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 749 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "Processing epoch : 750 / 750\n",
      "Extracting time courses for 68 labels (mode: mean_flip)\n",
      "[done]\n"
     ]
    }
   ],
   "source": [
    "labels = mne.read_labels_from_annot(mne_pp.subject)\n",
    "labels = [lbl for lbl in labels if lbl.name != 'unknown-lh']\n",
    "label_ts = mne.extract_label_time_course(stc_epochs, labels, src, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 68, 500)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(label_ts).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connectivity computation...\n",
      "only using indices for lower-triangular matrix\n",
      "    computing connectivity for 2278 connections\n",
      "    using t=0.000s..0.998s for estimation (500 points)\n",
      "    frequencies: 8.0Hz..13.0Hz (6 points)\n",
      "    connectivity scores will be averaged for each band\n",
      "    Using multitaper spectrum estimation with 7 DPSS windows\n",
      "    the following metrics will be computed: Coherence\n",
      "    computing connectivity for epochs 1..2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 3..4\n",
      "    computing connectivity for epochs 5..6\n",
      "    computing connectivity for epochs 7..8\n",
      "    computing connectivity for epochs 9..10\n",
      "    computing connectivity for epochs 11..12\n",
      "    computing connectivity for epochs 13..14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 15..16\n",
      "    computing connectivity for epochs 17..18\n",
      "    computing connectivity for epochs 19..20\n",
      "    computing connectivity for epochs 21..22\n",
      "    computing connectivity for epochs 23..24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 25..26\n",
      "    computing connectivity for epochs 27..28\n",
      "    computing connectivity for epochs 29..30\n",
      "    computing connectivity for epochs 31..32\n",
      "    computing connectivity for epochs 33..34\n",
      "    computing connectivity for epochs 35..36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 37..38\n",
      "    computing connectivity for epochs 39..40\n",
      "    computing connectivity for epochs 41..42\n",
      "    computing connectivity for epochs 43..44\n",
      "    computing connectivity for epochs 45..46\n",
      "    computing connectivity for epochs 47..48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 49..50\n",
      "    computing connectivity for epochs 51..52\n",
      "    computing connectivity for epochs 53..54\n",
      "    computing connectivity for epochs 55..56\n",
      "    computing connectivity for epochs 57..58\n",
      "    computing connectivity for epochs 59..60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 61..62\n",
      "    computing connectivity for epochs 63..64\n",
      "    computing connectivity for epochs 65..66\n",
      "    computing connectivity for epochs 67..68\n",
      "    computing connectivity for epochs 69..70\n",
      "    computing connectivity for epochs 71..72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 73..74\n",
      "    computing connectivity for epochs 75..76\n",
      "    computing connectivity for epochs 77..78\n",
      "    computing connectivity for epochs 79..80\n",
      "    computing connectivity for epochs 81..82\n",
      "    computing connectivity for epochs 83..84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 85..86\n",
      "    computing connectivity for epochs 87..88\n",
      "    computing connectivity for epochs 89..90\n",
      "    computing connectivity for epochs 91..92\n",
      "    computing connectivity for epochs 93..94\n",
      "    computing connectivity for epochs 95..96\n",
      "    computing connectivity for epochs 97..98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 99..100\n",
      "    computing connectivity for epochs 101..102\n",
      "    computing connectivity for epochs 103..104\n",
      "    computing connectivity for epochs 105..106\n",
      "    computing connectivity for epochs 107..108\n",
      "    computing connectivity for epochs 109..110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 111..112\n",
      "    computing connectivity for epochs 113..114\n",
      "    computing connectivity for epochs 115..116\n",
      "    computing connectivity for epochs 117..118\n",
      "    computing connectivity for epochs 119..120\n",
      "    computing connectivity for epochs 121..122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 123..124\n",
      "    computing connectivity for epochs 125..126\n",
      "    computing connectivity for epochs 127..128\n",
      "    computing connectivity for epochs 129..130\n",
      "    computing connectivity for epochs 131..132\n",
      "    computing connectivity for epochs 133..134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 135..136\n",
      "    computing connectivity for epochs 137..138\n",
      "    computing connectivity for epochs 139..140\n",
      "    computing connectivity for epochs 141..142\n",
      "    computing connectivity for epochs 143..144\n",
      "    computing connectivity for epochs 145..146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 147..148\n",
      "    computing connectivity for epochs 149..150\n",
      "    computing connectivity for epochs 151..152\n",
      "    computing connectivity for epochs 153..154\n",
      "    computing connectivity for epochs 155..156\n",
      "    computing connectivity for epochs 157..158\n",
      "    computing connectivity for epochs 159..160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 161..162\n",
      "    computing connectivity for epochs 163..164\n",
      "    computing connectivity for epochs 165..166\n",
      "    computing connectivity for epochs 167..168\n",
      "    computing connectivity for epochs 169..170\n",
      "    computing connectivity for epochs 171..172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 173..174\n",
      "    computing connectivity for epochs 175..176\n",
      "    computing connectivity for epochs 177..178\n",
      "    computing connectivity for epochs 179..180\n",
      "    computing connectivity for epochs 181..182\n",
      "    computing connectivity for epochs 183..184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 185..186\n",
      "    computing connectivity for epochs 187..188\n",
      "    computing connectivity for epochs 189..190\n",
      "    computing connectivity for epochs 191..192\n",
      "    computing connectivity for epochs 193..194\n",
      "    computing connectivity for epochs 195..196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 197..198\n",
      "    computing connectivity for epochs 199..200\n",
      "    computing connectivity for epochs 201..202\n",
      "    computing connectivity for epochs 203..204\n",
      "    computing connectivity for epochs 205..206\n",
      "    computing connectivity for epochs 207..208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 209..210\n",
      "    computing connectivity for epochs 211..212\n",
      "    computing connectivity for epochs 213..214\n",
      "    computing connectivity for epochs 215..216\n",
      "    computing connectivity for epochs 217..218\n",
      "    computing connectivity for epochs 219..220\n",
      "    computing connectivity for epochs 221..222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 223..224\n",
      "    computing connectivity for epochs 225..226\n",
      "    computing connectivity for epochs 227..228\n",
      "    computing connectivity for epochs 229..230\n",
      "    computing connectivity for epochs 231..232\n",
      "    computing connectivity for epochs 233..234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 235..236\n",
      "    computing connectivity for epochs 237..238\n",
      "    computing connectivity for epochs 239..240\n",
      "    computing connectivity for epochs 241..242\n",
      "    computing connectivity for epochs 243..244\n",
      "    computing connectivity for epochs 245..246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 247..248\n",
      "    computing connectivity for epochs 249..250\n",
      "    computing connectivity for epochs 251..252\n",
      "    computing connectivity for epochs 253..254\n",
      "    computing connectivity for epochs 255..256\n",
      "    computing connectivity for epochs 257..258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 259..260\n",
      "    computing connectivity for epochs 261..262\n",
      "    computing connectivity for epochs 263..264\n",
      "    computing connectivity for epochs 265..266\n",
      "    computing connectivity for epochs 267..268\n",
      "    computing connectivity for epochs 269..270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 271..272\n",
      "    computing connectivity for epochs 273..274\n",
      "    computing connectivity for epochs 275..276\n",
      "    computing connectivity for epochs 277..278\n",
      "    computing connectivity for epochs 279..280\n",
      "    computing connectivity for epochs 281..282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 283..284\n",
      "    computing connectivity for epochs 285..286\n",
      "    computing connectivity for epochs 287..288\n",
      "    computing connectivity for epochs 289..290\n",
      "    computing connectivity for epochs 291..292\n",
      "    computing connectivity for epochs 293..294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 295..296\n",
      "    computing connectivity for epochs 297..298\n",
      "    computing connectivity for epochs 299..300\n",
      "    computing connectivity for epochs 301..302\n",
      "    computing connectivity for epochs 303..304\n",
      "    computing connectivity for epochs 305..306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 307..308\n",
      "    computing connectivity for epochs 309..310\n",
      "    computing connectivity for epochs 311..312\n",
      "    computing connectivity for epochs 313..314\n",
      "    computing connectivity for epochs 315..316\n",
      "    computing connectivity for epochs 317..318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 319..320\n",
      "    computing connectivity for epochs 321..322\n",
      "    computing connectivity for epochs 323..324\n",
      "    computing connectivity for epochs 325..326\n",
      "    computing connectivity for epochs 327..328\n",
      "    computing connectivity for epochs 329..330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 331..332\n",
      "    computing connectivity for epochs 333..334\n",
      "    computing connectivity for epochs 335..336\n",
      "    computing connectivity for epochs 337..338\n",
      "    computing connectivity for epochs 339..340\n",
      "    computing connectivity for epochs 341..342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 343..344\n",
      "    computing connectivity for epochs 345..346\n",
      "    computing connectivity for epochs 347..348\n",
      "    computing connectivity for epochs 349..350\n",
      "    computing connectivity for epochs 351..352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 353..354\n",
      "    computing connectivity for epochs 355..356\n",
      "    computing connectivity for epochs 357..358\n",
      "    computing connectivity for epochs 359..360\n",
      "    computing connectivity for epochs 361..362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 363..364\n",
      "    computing connectivity for epochs 365..366\n",
      "    computing connectivity for epochs 367..368\n",
      "    computing connectivity for epochs 369..370\n",
      "    computing connectivity for epochs 371..372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 373..374\n",
      "    computing connectivity for epochs 375..376\n",
      "    computing connectivity for epochs 377..378\n",
      "    computing connectivity for epochs 379..380\n",
      "    computing connectivity for epochs 381..382\n",
      "    computing connectivity for epochs 383..384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 385..386\n",
      "    computing connectivity for epochs 387..388\n",
      "    computing connectivity for epochs 389..390\n",
      "    computing connectivity for epochs 391..392\n",
      "    computing connectivity for epochs 393..394\n",
      "    computing connectivity for epochs 395..396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 397..398\n",
      "    computing connectivity for epochs 399..400\n",
      "    computing connectivity for epochs 401..402\n",
      "    computing connectivity for epochs 403..404\n",
      "    computing connectivity for epochs 405..406\n",
      "    computing connectivity for epochs 407..408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 409..410\n",
      "    computing connectivity for epochs 411..412\n",
      "    computing connectivity for epochs 413..414\n",
      "    computing connectivity for epochs 415..416\n",
      "    computing connectivity for epochs 417..418\n",
      "    computing connectivity for epochs 419..420\n",
      "    computing connectivity for epochs 421..422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 423..424\n",
      "    computing connectivity for epochs 425..426\n",
      "    computing connectivity for epochs 427..428\n",
      "    computing connectivity for epochs 429..430\n",
      "    computing connectivity for epochs 431..432\n",
      "    computing connectivity for epochs 433..434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 435..436\n",
      "    computing connectivity for epochs 437..438\n",
      "    computing connectivity for epochs 439..440\n",
      "    computing connectivity for epochs 441..442\n",
      "    computing connectivity for epochs 443..444\n",
      "    computing connectivity for epochs 445..446\n",
      "    computing connectivity for epochs 447..448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 449..450\n",
      "    computing connectivity for epochs 451..452\n",
      "    computing connectivity for epochs 453..454\n",
      "    computing connectivity for epochs 455..456\n",
      "    computing connectivity for epochs 457..458\n",
      "    computing connectivity for epochs 459..460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 461..462\n",
      "    computing connectivity for epochs 463..464\n",
      "    computing connectivity for epochs 465..466\n",
      "    computing connectivity for epochs 467..468\n",
      "    computing connectivity for epochs 469..470\n",
      "    computing connectivity for epochs 471..472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 473..474\n",
      "    computing connectivity for epochs 475..476\n",
      "    computing connectivity for epochs 477..478\n",
      "    computing connectivity for epochs 479..480\n",
      "    computing connectivity for epochs 481..482\n",
      "    computing connectivity for epochs 483..484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 485..486\n",
      "    computing connectivity for epochs 487..488\n",
      "    computing connectivity for epochs 489..490\n",
      "    computing connectivity for epochs 491..492\n",
      "    computing connectivity for epochs 493..494\n",
      "    computing connectivity for epochs 495..496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 497..498\n",
      "    computing connectivity for epochs 499..500\n",
      "    computing connectivity for epochs 501..502\n",
      "    computing connectivity for epochs 503..504\n",
      "    computing connectivity for epochs 505..506\n",
      "    computing connectivity for epochs 507..508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 509..510\n",
      "    computing connectivity for epochs 511..512\n",
      "    computing connectivity for epochs 513..514\n",
      "    computing connectivity for epochs 515..516\n",
      "    computing connectivity for epochs 517..518\n",
      "    computing connectivity for epochs 519..520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 521..522\n",
      "    computing connectivity for epochs 523..524\n",
      "    computing connectivity for epochs 525..526\n",
      "    computing connectivity for epochs 527..528\n",
      "    computing connectivity for epochs 529..530\n",
      "    computing connectivity for epochs 531..532\n",
      "    computing connectivity for epochs 533..534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 535..536\n",
      "    computing connectivity for epochs 537..538\n",
      "    computing connectivity for epochs 539..540\n",
      "    computing connectivity for epochs 541..542\n",
      "    computing connectivity for epochs 543..544\n",
      "    computing connectivity for epochs 545..546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 547..548\n",
      "    computing connectivity for epochs 549..550\n",
      "    computing connectivity for epochs 551..552\n",
      "    computing connectivity for epochs 553..554\n",
      "    computing connectivity for epochs 555..556\n",
      "    computing connectivity for epochs 557..558\n",
      "    computing connectivity for epochs 559..560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 561..562\n",
      "    computing connectivity for epochs 563..564\n",
      "    computing connectivity for epochs 565..566\n",
      "    computing connectivity for epochs 567..568\n",
      "    computing connectivity for epochs 569..570\n",
      "    computing connectivity for epochs 571..572\n",
      "    computing connectivity for epochs 573..574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 575..576\n",
      "    computing connectivity for epochs 577..578\n",
      "    computing connectivity for epochs 579..580\n",
      "    computing connectivity for epochs 581..582\n",
      "    computing connectivity for epochs 583..584\n",
      "    computing connectivity for epochs 585..586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 587..588\n",
      "    computing connectivity for epochs 589..590\n",
      "    computing connectivity for epochs 591..592\n",
      "    computing connectivity for epochs 593..594\n",
      "    computing connectivity for epochs 595..596\n",
      "    computing connectivity for epochs 597..598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 599..600\n",
      "    computing connectivity for epochs 601..602\n",
      "    computing connectivity for epochs 603..604\n",
      "    computing connectivity for epochs 605..606\n",
      "    computing connectivity for epochs 607..608\n",
      "    computing connectivity for epochs 609..610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 611..612\n",
      "    computing connectivity for epochs 613..614\n",
      "    computing connectivity for epochs 615..616\n",
      "    computing connectivity for epochs 617..618\n",
      "    computing connectivity for epochs 619..620\n",
      "    computing connectivity for epochs 621..622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 623..624\n",
      "    computing connectivity for epochs 625..626\n",
      "    computing connectivity for epochs 627..628\n",
      "    computing connectivity for epochs 629..630\n",
      "    computing connectivity for epochs 631..632\n",
      "    computing connectivity for epochs 633..634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 635..636\n",
      "    computing connectivity for epochs 637..638\n",
      "    computing connectivity for epochs 639..640\n",
      "    computing connectivity for epochs 641..642\n",
      "    computing connectivity for epochs 643..644\n",
      "    computing connectivity for epochs 645..646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 647..648\n",
      "    computing connectivity for epochs 649..650\n",
      "    computing connectivity for epochs 651..652\n",
      "    computing connectivity for epochs 653..654\n",
      "    computing connectivity for epochs 655..656\n",
      "    computing connectivity for epochs 657..658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 659..660\n",
      "    computing connectivity for epochs 661..662\n",
      "    computing connectivity for epochs 663..664\n",
      "    computing connectivity for epochs 665..666\n",
      "    computing connectivity for epochs 667..668\n",
      "    computing connectivity for epochs 669..670\n",
      "    computing connectivity for epochs 671..672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 673..674\n",
      "    computing connectivity for epochs 675..676\n",
      "    computing connectivity for epochs 677..678\n",
      "    computing connectivity for epochs 679..680\n",
      "    computing connectivity for epochs 681..682\n",
      "    computing connectivity for epochs 683..684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 685..686\n",
      "    computing connectivity for epochs 687..688\n",
      "    computing connectivity for epochs 689..690\n",
      "    computing connectivity for epochs 691..692\n",
      "    computing connectivity for epochs 693..694\n",
      "    computing connectivity for epochs 695..696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 697..698\n",
      "    computing connectivity for epochs 699..700\n",
      "    computing connectivity for epochs 701..702\n",
      "    computing connectivity for epochs 703..704\n",
      "    computing connectivity for epochs 705..706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 707..708\n",
      "    computing connectivity for epochs 709..710\n",
      "    computing connectivity for epochs 711..712\n",
      "    computing connectivity for epochs 713..714\n",
      "    computing connectivity for epochs 715..716\n",
      "    computing connectivity for epochs 717..718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 719..720\n",
      "    computing connectivity for epochs 721..722\n",
      "    computing connectivity for epochs 723..724\n",
      "    computing connectivity for epochs 725..726\n",
      "    computing connectivity for epochs 727..728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 729..730\n",
      "    computing connectivity for epochs 731..732\n",
      "    computing connectivity for epochs 733..734\n",
      "    computing connectivity for epochs 735..736\n",
      "    computing connectivity for epochs 737..738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 739..740\n",
      "    computing connectivity for epochs 741..742\n",
      "    computing connectivity for epochs 743..744\n",
      "    computing connectivity for epochs 745..746\n",
      "    computing connectivity for epochs 747..748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    computing connectivity for epochs 749..750\n",
      "    assembling connectivity matrix (filling the upper triangular region of the matrix)\n",
      "[Connectivity computation done]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "con_methods = ['coh']\n",
    "con, freqs, times, n_epochs, n_tapers = mne.connectivity.spectral_connectivity(\n",
    "    label_ts, method=con_methods, mode='multitaper', sfreq=500, fmin=8, fmax=13,\n",
    "    faverage=True, mt_adaptive=True, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1c4a6dc390>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(con[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stcs = mne_pp.generate_event_wise_stcs(epochs, evokeds, montage, src, bem, gen_mode = False, save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stcs_cp = mne_pp.apply_cortical_parcellation_event_stcs(stcs, src, save=False, gen_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne_pp.epochs_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con[:,:,0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
